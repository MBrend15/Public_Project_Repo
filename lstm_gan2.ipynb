{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d9ebd-ce9a-4150-8fc4-cbe0a4eecc31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f752d7-2f69-493b-a03a-0acb4db74db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295239d-3d08-4f7d-bef1-1de64e1d0b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fc124-d080-4ff2-8c79-9918822704ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = spark.read.parquet(*[\"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep3/*\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e704df-8177-4e3d-8436-16f3e46e533c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tot = ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20dd31f-3f4c-4b1d-9213-29859381e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.groupBy(\"mal_trace\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'cnt_per_group') \\\n",
    "    .withColumn('perc_of_count_total', (col('cnt_per_group') / tot) * 100 ) \\\n",
    "    .sort(\"perc_of_count_total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51475f9f-73c6-477b-a45e-d3f76a3d4d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "embedding_dim = 64\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 30\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d53c55-83ec-4b3f-929b-dc66f0fb3a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb58e17-1e00-4ad8-a799-9a6d250f6597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_events = ds.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9cc65-f4eb-4612-b0c2-ec4d4e640779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get vocab for full dataset \n",
    "tokenizer.fit_on_texts(ds_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992eb682-a6c9-490c-8426-46248ea03038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_lim = ds.limit(num_samples).cache()\n",
    "ds_events = ds_lim.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504683e-0e1b-43ac-bb24-eb36db222491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get only malicious data\n",
    "ds_mal = ds.filter( col('mal_trace') == 1).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172993cb-509d-4684-95da-b009d1eecde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm_events = ds_mal.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbefcd-dc85-4baa-b7bc-8bbe4b20eb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm_labels = ds_mal.select('mal_trace').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f64c30-5706-4ff5-b2e9-13610902d003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "vocab_count = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd067533-4120-48d6-b2be-44bc160470fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c7a56-505d-4d73-84f7-13c116291646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one hot encode the data\n",
    "dm_sequences = tokenizer.texts_to_sequences(dm_events)\n",
    "dm_padded = tf.keras.utils.pad_sequences(dm_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "seq_enc_tensor = tf.one_hot(dm_padded, vocab_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14821ad4-6aee-4d1c-9f73-9ed40bde1a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8916a0-1b14-4dd1-9554-e3bfceb6bfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13ccb8-4878-4a18-8d6b-523d98960f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842ecdb-06a1-4469-85bd-91dc0059f1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor.shape\n",
    "# shape - (input_len, sequence_length, vocab_size)\n",
    "input_len = seq_enc_tensor.shape[0]\n",
    "sequence_length = seq_enc_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b6f5d-1ae6-4632-8570-8b0751b5f695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_count, activation='softmax')),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "            tf.keras.layers.LSTM(128, return_sequences=False),\n",
    "            tf.keras.layers.Dense(2, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, sequence_length, vocab_count], minval=1, maxval=vocab_count, dtype=tf.int32)\n",
    "    return n\n",
    "\n",
    "def generate_fake_samples(generator):\n",
    "    # generate points in latent space & pass through generator\n",
    "    x = generator.predict(generate_latent_space(), verbose=0)\n",
    "    # create class labels\n",
    "    y = zeros((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def generate_real_samples():\n",
    "    x = seq_enc_tensor\n",
    "    # create class labels\n",
    "    y = ones((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def train(g_model, d_model, gan_model, epochs=5, n_eval=20):\n",
    "    d_acc_history = []\n",
    "    d_loss_history = []\n",
    "    g_acc_history = []\n",
    "    g_loss_history = []\n",
    "\n",
    "    d_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    g_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_fake_samples(g_model)\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model)\n",
    "\n",
    "        # update discriminator\n",
    "        d_real_loss = d_model.train_on_batch(x_real, y_real)\n",
    "        d_fake_loss = d_model.train_on_batch(x_fake, y_fake)\n",
    "        d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "\n",
    "        d_real_pred = d_model.predict_on_batch(x_real)\n",
    "        d_fake_pred = d_model.predict_on_batch(x_fake)\n",
    "\n",
    "        d_metric.update_state(tf.concat([y_real, y_fake], axis=0), tf.concat([d_real_pred, d_fake_pred], axis=0))\n",
    "        d_acc = d_metric.result().numpy()\n",
    "\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        y_gan = ones((input_len, 1))\n",
    "        g_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_pred = gan_model.predict_on_batch(x_gan)\n",
    "        g_metric.update_state(tf.one_hot(tf.cast(y_gan, tf.int32), depth=2), gan_pred)\n",
    "        g_acc = g_metric.result().numpy()\n",
    "\n",
    "        d_acc_history.append(d_acc)\n",
    "        d_loss_history.append(d_loss)\n",
    "        g_acc_history.append(g_acc)\n",
    "        g_loss_history.append(g_loss)\n",
    "\n",
    "        if i % n_eval == 0:\n",
    "            print(f\"Epoch {i}: Discriminator Loss: {d_loss}, Discriminator Accuracy: {d_acc}, Generator Loss: {g_loss}, Generator Accuracy: {g_acc}\")\n",
    "\n",
    "    return d_acc_history, d_loss_history, g_acc_history, g_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2bc25-832b-4b86-bf51-609dde91aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4068c3-bd4a-4228-9991-43cbdb8fce24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = define_generator()\n",
    "discriminator = define_discriminator()\n",
    "gan = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac1bc0d-2473-4ce0-97d7-2d04f20aaf8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a new sequence\n",
    "new_seq = generator.predict(seq_enc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d1929-f02c-42cb-864b-1176b16fa72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.train_on_batch(seq_enc_tensor, seq_enc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae0fdd-386e-420e-ac51-1d5821653eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a new sequence using the generator model\n",
    "new_seq_enc_tensor = generator.predict(seq_enc_tensor)\n",
    "new_seq_enc = tf.argmax(new_seq_enc_tensor, axis=-1)\n",
    "new_seq_texts = tokenizer.sequences_to_texts(new_seq_enc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e5ec2-d8ef-4250-9071-1027daafa267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_labels = np.ones((input_len,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126e79e-ed10-4117-a5f1-02165a3fb772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b86dda-bc30-4591-b94a-80d61b7c1616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_seq_enc_tensor[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142072af-ce41-42d2-8520-0429fbf9d8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_seq[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236b820-4eef-4d6d-8bb8-2f9b709dd2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_seq_enc_list = new_seq_enc_tensor.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d74b2-2656-4713-8898-30762b8cf7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[np.argmax(i, axis=-1) for i in new_seq_enc_list][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d355924-7490-42f8-8556-b8bb592d6931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(new_seq_texts[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55b181-7e07-4add-8cec-7b071fc0740a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator.train_on_batch(new_seq_enc_tensor, real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b66965-b009-4a50-ab8d-bc1a16e86c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator.predict(new_seq_enc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b836b-11fe-4164-a40a-b96a55f0392d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569faa1-b00f-4c68-ac4e-9bb10ea924cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c36d90-948d-4afe-a7fe-4cc5ceffa0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan.train_on_batch(new_seq_enc_tensor, real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab7c04-e0cd-4e7e-9226-43ac91672f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 101\n",
    "d_acc_history, d_loss_history, g_acc_history, g_loss_history = train(generator, discriminator, gan, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db84c0-205d-48e6-8cb0-9eed0fca944d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(range(1, epochs + 1), d_loss_history, label='Discriminator Loss')\n",
    "ax1.plot(range(1, epochs + 1), g_loss_history, label='Generator Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(1, epochs + 1), d_acc_history, label='Discriminator Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4b995-caab-4e73-9b5a-752cd170f276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1ae20-85d4-4ada-ab51-c5ed09ccf502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06485880-166d-4d86-8584-c17036bcc3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
