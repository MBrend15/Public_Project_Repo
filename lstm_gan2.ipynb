{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2b902e-30fe-4959-ae55-af69f8df4a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "# https://stackoverflow.com/questions/58352326/running-the-tensorflow-2-0-code-gives-valueerror-tf-function-decorated-functio\n",
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c731b5c-936b-4ca1-ba92-6d886fcca913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "embedding_dim = 64\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 10000\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "training_portion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb956bf-6baa-4f8e-9c83-406b29f6d49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-bb5fb0f4-5cff-4d17-872f-a86081fb4d97;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 303ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-bb5fb0f4-5cff-4d17-872f-a86081fb4d97\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/5ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 04:09:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 04:09:51 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/04/10 04:09:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# prepare real data\n",
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d3f787-a592-490d-b367-ec519f653b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet(*[\"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep3/*\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8328746-3ffc-462d-a489-fa85bb87dfee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_real_samples(ds, lc=300):\n",
    "    # Calculate the number of malicious and non-malicious records\n",
    "    malicious_ds = ds.filter(col(\"malicious\") == 1).limit(lc)\n",
    "    ds_events = malicious_ds.select('event_sequence').rdd.flatMap(lambda x: x).collect()\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    # Get our training data word index\n",
    "    tokenizer.fit_on_texts(ds_events)\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_count = len(word_index)\n",
    "    train_sequences = tokenizer.texts_to_sequences(ds_events)\n",
    "    train_padded = tf.keras.utils.pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    train_ds = tf.reshape(train_padded, (-1, len(train_padded), 6, 1, 1))\n",
    "    train_labels_ds = ones((1, input_len, 6, 1, 1))\n",
    "    return train_ds, train_labels_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d543fa9-75aa-46e9-8e05-011c5d6e160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb441b7-a022-4d48-bc1f-da59f5940893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4990288f-c540-4f30-8411-ae99dfabc4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e75224e-867c-4ec5-ae9f-2e6155ac6f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of samples to make\n",
    "input_len = 500\n",
    "\n",
    "# vocab size as defined in the lstm tokenizer\n",
    "num_words = 1000 \n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0034ad-65ed-4ae3-840f-893a64c53d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "500e58b6-431a-4eb6-b027-c8fceb138886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator(vocab_size=input_len):\n",
    "    # Define the input layer\n",
    "    inputs = tf.keras.Input(shape=(500, 6, 1))\n",
    "    \n",
    "    # Flatten the input data\n",
    "    flat_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    \n",
    "    # Add the Embedding layer\n",
    "    embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=500 * 6)(flat_inputs)\n",
    "    \n",
    "    # Add the GRU layer\n",
    "    gru_out, state = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)(embedding)\n",
    "    \n",
    "    # Add the Dense layer\n",
    "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(gru_out)\n",
    "    \n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1790003-903f-4da5-b735-5ea2b56071cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(input_shape):\n",
    "    # Define the input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Add the dense layer with LeakyReLU activation\n",
    "    dense = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)(dense)\n",
    "    \n",
    "    # Add the dense layer with LeakyReLU activation\n",
    "    dense = tf.keras.layers.Dense(256, activation='relu')(leaky_relu)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)(dense)\n",
    "    \n",
    "    # Add the dense layer with sigmoid activation\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(leaky_relu)\n",
    "    \n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa17c43e-7f48-462d-8785-e92f7bb8892e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a0a004-b31e-4a29-a656-c12180be7d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, 6, 1], minval=1, maxval=100, dtype=tf.int32)\n",
    "    n_ds = tf.reshape(n, (-1, input_len, 6, 1))\n",
    "    return n_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0770da69-fbef-4af6-ab74-60d7e765cbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim=3, n=0):\n",
    "    # generate points in latent space\n",
    "    n_ds = generate_latent_space()\n",
    "    # predict outputs\n",
    "    X = generator.predict(n_ds, verbose=0)\n",
    "    print(\"size of output from generator\")\n",
    "    print(X.shape)\n",
    "    # add extra dimension to output tensor\n",
    "    X = tf.expand_dims(X, axis=-1)\n",
    "    print(\"size of input to discriminator after expansion\")\n",
    "    print(X.shape)\n",
    "    # create class labels\n",
    "    y = zeros((1, input_len, 6, 1, 1))\n",
    "    print(\"size of labels to discriminator\")\n",
    "    print(y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5edda647-6054-495d-b1c9-63440b1a58d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def train(g_model, d_model, gan_model, latent_dim=3, n_epochs=5, n_batch=128, n_eval=200):\n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # prepare real samples\n",
    "        # x_real, y_real = generate_fake_samples(g_model, input_len)\n",
    "        x_real, y_real = prepare_real_samples(data, lc=input_len)\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, input_len)\n",
    "        # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((1, input_len, 6, 1))\n",
    "        # create inverted labels for the fake samples\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "        # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            plt.title('Number of epochs = %i'%(i+1))\n",
    "            pred_data = generate_fake_samples(generator, input_len)[0]\n",
    "            real_data  = generate_fake_samples(generator, input_len)[0]\n",
    "            plt.plot(pred_data[0],'.',label='Random Fake Sample',color='firebrick')\n",
    "            plt.plot(real_data[0],'.',label = 'Random Real Sample',color='navy')\n",
    "            plt.legend(fontsize=10)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44270b-c126-4e2d-a73e-b7a63fba8dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d4156-4174-4e11-8b8a-0e783bc68454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27598b89-0951-474e-a361-9c23e2edccfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3234/66873978.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test combination of generator and discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3234/3422384084.py\u001b[0m in \u001b[0;36mdefine_generator\u001b[0;34m(vocab_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Add the GRU layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgru_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Add the Dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mrandom_normal\u001b[0;34m(self, shape, mean, stddev, dtype, nonce)\u001b[0m\n\u001b[1;32m   2059\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             return tf.random.stateless_normal(\n\u001b[0m\u001b[1;32m   2062\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "# Test combination of generator and discriminator\n",
    "generator = define_generator()\n",
    "discriminator = define_discriminator()\n",
    "gan = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3fb90-8747-4cd1-9bd1-3187905c754f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9da932-64e2-4249-bcfb-aea9adb4ae29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_real, y_real = generate_fake_samples(ge, input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531ebb3-5a7c-4876-9be3-41ecd45e2363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d74c0-9ccc-4e89-852c-349b073f0522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a431c4d-d7b1-461d-8b9c-e58a3cbf07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrimina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06968726-14c4-41f8-a9cb-044473a76cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ecb90b-789d-434b-a83d-21dbe176893b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g2 = define_gen2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5873433-a244-4668-abe8-cdf3bb95b2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_real, y_real = generate_fake_samples(g2, input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87c8d3-ccca-451f-b21f-c5ec3f0f167e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ge.predict(x_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf02b4-95cb-4631-b087-f38a1ae0b8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09540da-4b61-42f8-9863-e15c6c8d5a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use discriminator with generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e7bcb-7a5c-48ad-8880-dd7039cdb79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator.train_on_batch(x_real, y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39736d72-52ee-4d28-ba9e-e5f03a19852f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test gan created data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745f261-9ab3-4951-8ee4-37bd86d3a915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_gan = generate_latent_space()\n",
    "# x_gan = tf.reshape(x_gan, (-1, input_len, 6, 1, 1))\n",
    "# create inverted labels for the fake samples\n",
    "y_gan = ones(([1,input_len, 6, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4defae-dd10-4d15-a1eb-6f1c48aa2f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e4b6f6-dfaa-4eb0-803a-aba2e6e4662c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412866b-31f7-4982-a797-079fbf268c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator.train_on_batch(x_gan, y_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31845f7-471a-4968-a2ef-08573e257720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d803ad-611e-41fc-9bbb-d27713b385a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan.train_on_batch(x_gan, y_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563cf8d-39d9-4043-8130-9da6a09b4975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6636408-9b19-4ed7-aa46-2dbd536131af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c08ecc-1b3a-4ca4-8c8d-fc876158effb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(generator, discriminator, gan, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bc4d4-1d7b-427c-b332-6afa13a59374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b601b-9ddf-4693-b560-ab8a505a0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data based on the trained model\n",
    "si = generate_latent_space()\n",
    "sp = gan.predict(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed3831-299e-4e04-83f6-0590bcbbea33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadde8f3-3b4c-4746-90f1-cc0d268e98aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp_ds = tf.reshape(sp, (input_len, 6, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a54f9-3a98-494a-acca-1997df07940e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73575aa-5c7f-4cb8-82a0-b78558484448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.max(sp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaff0cc-5c61-48fd-b81a-428ef0810fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.max(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169b4c5-d9df-4a61-a7ac-32a13dd25b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
