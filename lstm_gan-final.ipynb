{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4d9ebd-ce9a-4150-8fc4-cbe0a4eecc31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-61210d25-8d89-4b49-a80d-a2e7b850f3c8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 98ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-61210d25-8d89-4b49-a80d-a2e7b850f3c8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/15 22:36:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/15 22:36:25 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f752d7-2f69-493b-a03a-0acb4db74db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295239d-3d08-4f7d-bef1-1de64e1d0b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64fc124-d080-4ff2-8c79-9918822704ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ds = spark.read.parquet(*[\"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep3/*\"]) \\\n",
    "                .withColumn(\"event_sequence\",col('event_sequence').cast('string')) \\\n",
    "                .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e704df-8177-4e3d-8436-16f3e46e533c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tot = ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20dd31f-3f4c-4b1d-9213-29859381e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------------+\n",
      "|mal_trace|cnt_per_group|perc_of_count_total|\n",
      "+---------+-------------+-------------------+\n",
      "|        1|       118763| 0.6835843967111419|\n",
      "|        0|     17254805|  99.31641560328886|\n",
      "+---------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.groupBy(\"mal_trace\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'cnt_per_group') \\\n",
    "    .withColumn('perc_of_count_total', (col('cnt_per_group') / tot) * 100 ) \\\n",
    "    .sort(\"perc_of_count_total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51475f9f-73c6-477b-a45e-d3f76a3d4d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 6\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23d53c55-83ec-4b3f-929b-dc66f0fb3a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceb58e17-1e00-4ad8-a799-9a6d250f6597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ds_events = ds.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcf9cc65-f4eb-4612-b0c2-ec4d4e640779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get vocab for full dataset \n",
    "tokenizer.fit_on_texts(ds_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "992eb682-a6c9-490c-8426-46248ea03038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_lim = ds.limit(num_samples).cache()\n",
    "ds_events = ds_lim.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5504683e-0e1b-43ac-bb24-eb36db222491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trace: bigint, mal_trace: int, malicious: int, event_sequence: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only malicious data\n",
    "ds_mal = ds.filter( col('mal_trace') == 1).cache()\n",
    "ds.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "172993cb-509d-4684-95da-b009d1eecde5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dm_events = ds_mal.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bbbefcd-dc85-4baa-b7bc-8bbe4b20eb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm_labels = ds_mal.select('mal_trace').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83f64c30-5706-4ff5-b2e9-13610902d003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "vocab_count = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd067533-4120-48d6-b2be-44bc160470fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a8c7a56-505d-4d73-84f7-13c116291646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one hot encode the data\n",
    "dm_sequences = tokenizer.texts_to_sequences(dm_events)\n",
    "dm_padded = tf.keras.utils.pad_sequences(dm_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "seq_enc_tensor = tf.one_hot(dm_padded, vocab_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "019d9a6c-c137-4194-bed7-a5e1beb27c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(event_sequence='[01000000000100000100010000100000000000001, 10000000000010000010100001000000000001000, 10000000000100001000100001000000000010000]')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_lim.select('event_sequence').limit(1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37d7b4-4190-41d3-b885-22557ff0ea43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14821ad4-6aee-4d1c-9f73-9ed40bde1a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 111), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_enc_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8916a0-1b14-4dd1-9554-e3bfceb6bfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b13ccb8-4878-4a18-8d6b-523d98960f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([118763, 6, 111])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_enc_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0842ecdb-06a1-4469-85bd-91dc0059f1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor.shape\n",
    "# shape - (input_len, sequence_length, vocab_size)\n",
    "input_len = seq_enc_tensor.shape[0]\n",
    "sequence_length = seq_enc_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f76b6f5d-1ae6-4632-8570-8b0751b5f695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_count, activation='softmax')),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "            tf.keras.layers.LSTM(128, return_sequences=False),\n",
    "            tf.keras.layers.Dense(2, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, sequence_length, vocab_count], minval=1, maxval=vocab_count, dtype=tf.int32)\n",
    "    return n\n",
    "\n",
    "def generate_fake_samples(generator):\n",
    "    # generate points in latent space & pass through generator\n",
    "    x = generator.predict(generate_latent_space(), verbose=0)\n",
    "    # create class labels\n",
    "    y = zeros((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def generate_real_samples():\n",
    "    x = seq_enc_tensor\n",
    "    # create class labels\n",
    "    y = ones((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def train(g_model, d_model, gan_model, epochs=5, n_eval=20):\n",
    "    d_acc_history = []\n",
    "    d_loss_history = []\n",
    "    g_acc_history = []\n",
    "    g_loss_history = []\n",
    "\n",
    "    d_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    g_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_fake_samples(g_model)\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model)\n",
    "\n",
    "        # update discriminator\n",
    "        d_real_loss = d_model.train_on_batch(x_real, y_real)\n",
    "        d_fake_loss = d_model.train_on_batch(x_fake, y_fake)\n",
    "        d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "\n",
    "        d_real_pred = d_model.predict_on_batch(x_real)\n",
    "        d_fake_pred = d_model.predict_on_batch(x_fake)\n",
    "\n",
    "        d_metric.update_state(tf.concat([y_real, y_fake], axis=0), tf.concat([d_real_pred, d_fake_pred], axis=0))\n",
    "        d_acc = d_metric.result().numpy()\n",
    "\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        y_gan = ones((input_len, 1))\n",
    "        g_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_pred = gan_model.predict_on_batch(x_gan)\n",
    "        g_metric.update_state(tf.one_hot(tf.cast(y_gan, tf.int32), depth=2), gan_pred)\n",
    "        g_acc = g_metric.result().numpy()\n",
    "\n",
    "        d_acc_history.append(d_acc)\n",
    "        d_loss_history.append(d_loss)\n",
    "        g_acc_history.append(g_acc)\n",
    "        g_loss_history.append(g_loss)\n",
    "\n",
    "        if i % n_eval == 0:\n",
    "            print(f\"Epoch {i}: Discriminator Loss: {d_loss}, Discriminator Accuracy: {d_acc}, Generator Loss: {g_loss}, Generator Accuracy: {g_acc}\")\n",
    "\n",
    "    return d_acc_history, d_loss_history, g_acc_history, g_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2bc25-832b-4b86-bf51-609dde91aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a4068c3-bd4a-4228-9991-43cbdb8fce24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = define_generator()\n",
    "discriminator = define_discriminator()\n",
    "gan = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7ab7c04-e0cd-4e7e-9226-43ac91672f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32), but the yielded element was [[[0.00784405 0.01363464 0.00795084 ... 0.00616735 0.01232874 0.00930799]\n  [0.00743604 0.01299697 0.00657471 ... 0.00857116 0.01247007 0.01078571]\n  [0.00660481 0.00816573 0.00864302 ... 0.00780875 0.01493056 0.01225976]\n  [0.01089922 0.00896515 0.0062316  ... 0.00620996 0.0120111  0.00710753]\n  [0.00853574 0.0143795  0.0166215  ... 0.00633353 0.01574256 0.00595049]\n  [0.01126612 0.01166151 0.00304855 ... 0.00881959 0.0092577  0.00451845]]\n\n [[0.00901932 0.01744283 0.0126614  ... 0.0051707  0.0067511  0.01264073]\n  [0.00937799 0.01681233 0.00838365 ... 0.00519401 0.01234819 0.00877401]\n  [0.01010063 0.01713853 0.00942147 ... 0.00670861 0.01917028 0.0098217 ]\n  [0.00698665 0.01906229 0.00689812 ... 0.00844652 0.00837909 0.00722283]\n  [0.00642558 0.00801662 0.00641306 ... 0.00865609 0.00958089 0.0129503 ]\n  [0.012514   0.00982862 0.00653447 ... 0.01629108 0.00858043 0.01294903]]\n\n [[0.01168932 0.01072754 0.00446282 ... 0.01017345 0.01357007 0.0075546 ]\n  [0.00711788 0.02343464 0.00823045 ... 0.00713765 0.01143885 0.00887725]\n  [0.00726337 0.01336324 0.01039504 ... 0.00479237 0.01452046 0.01611213]\n  [0.00844331 0.01957811 0.00758222 ... 0.00822655 0.01099372 0.00893688]\n  [0.01294964 0.01274304 0.00759487 ... 0.01699475 0.01217456 0.00511607]\n  [0.01069593 0.00999451 0.01246619 ... 0.01275391 0.00916322 0.01002251]]\n\n ...\n\n [[0.0071698  0.01665911 0.01019003 ... 0.00534528 0.01018087 0.00948511]\n  [0.00602717 0.01360997 0.0104102  ... 0.00674121 0.00906293 0.01796024]\n  [0.00478603 0.0110727  0.00610275 ... 0.00517731 0.01377118 0.01704021]\n  [0.00670524 0.01187402 0.00813616 ... 0.01004024 0.01256021 0.01039293]\n  [0.00617699 0.01069959 0.00663627 ... 0.00709241 0.01170715 0.0083324 ]\n  [0.00680568 0.01763043 0.01094075 ... 0.01005474 0.01359353 0.0070264 ]]\n\n [[0.00560598 0.01862064 0.00643899 ... 0.01564105 0.00751078 0.01364231]\n  [0.00730061 0.01720654 0.00569534 ... 0.00774755 0.01834954 0.01045312]\n  [0.01243223 0.01369837 0.00852198 ... 0.00909312 0.01128154 0.0063348 ]\n  [0.00629803 0.02141227 0.00831497 ... 0.00662649 0.02291891 0.0074902 ]\n  [0.01139779 0.01380648 0.01799767 ... 0.00533533 0.01638228 0.00993858]\n  [0.00746125 0.00976811 0.01449763 ... 0.00673519 0.01113056 0.00573259]]\n\n [[0.00866404 0.0106354  0.00790299 ... 0.00938455 0.00953305 0.00871722]\n  [0.0067823  0.01704649 0.00853296 ... 0.00961295 0.00982589 0.01174172]\n  [0.00463716 0.02216605 0.00772885 ... 0.00809792 0.00928158 0.0097446 ]\n  [0.00792143 0.02060956 0.01374969 ... 0.00686169 0.01472474 0.00934699]\n  [0.00460164 0.01596515 0.01950155 ... 0.0045944  0.01449619 0.0141474 ]\n  [0.00820918 0.01899235 0.00893106 ... 0.00505789 0.01207003 0.01020742]]].\nTraceback (most recent call last):\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1045, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'ndarray'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1047, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32), but the yielded element was [[[0.00784405 0.01363464 0.00795084 ... 0.00616735 0.01232874 0.00930799]\n  [0.00743604 0.01299697 0.00657471 ... 0.00857116 0.01247007 0.01078571]\n  [0.00660481 0.00816573 0.00864302 ... 0.00780875 0.01493056 0.01225976]\n  [0.01089922 0.00896515 0.0062316  ... 0.00620996 0.0120111  0.00710753]\n  [0.00853574 0.0143795  0.0166215  ... 0.00633353 0.01574256 0.00595049]\n  [0.01126612 0.01166151 0.00304855 ... 0.00881959 0.0092577  0.00451845]]\n\n [[0.00901932 0.01744283 0.0126614  ... 0.0051707  0.0067511  0.01264073]\n  [0.00937799 0.01681233 0.00838365 ... 0.00519401 0.01234819 0.00877401]\n  [0.01010063 0.01713853 0.00942147 ... 0.00670861 0.01917028 0.0098217 ]\n  [0.00698665 0.01906229 0.00689812 ... 0.00844652 0.00837909 0.00722283]\n  [0.00642558 0.00801662 0.00641306 ... 0.00865609 0.00958089 0.0129503 ]\n  [0.012514   0.00982862 0.00653447 ... 0.01629108 0.00858043 0.01294903]]\n\n [[0.01168932 0.01072754 0.00446282 ... 0.01017345 0.01357007 0.0075546 ]\n  [0.00711788 0.02343464 0.00823045 ... 0.00713765 0.01143885 0.00887725]\n  [0.00726337 0.01336324 0.01039504 ... 0.00479237 0.01452046 0.01611213]\n  [0.00844331 0.01957811 0.00758222 ... 0.00822655 0.01099372 0.00893688]\n  [0.01294964 0.01274304 0.00759487 ... 0.01699475 0.01217456 0.00511607]\n  [0.01069593 0.00999451 0.01246619 ... 0.01275391 0.00916322 0.01002251]]\n\n ...\n\n [[0.0071698  0.01665911 0.01019003 ... 0.00534528 0.01018087 0.00948511]\n  [0.00602717 0.01360997 0.0104102  ... 0.00674121 0.00906293 0.01796024]\n  [0.00478603 0.0110727  0.00610275 ... 0.00517731 0.01377118 0.01704021]\n  [0.00670524 0.01187402 0.00813616 ... 0.01004024 0.01256021 0.01039293]\n  [0.00617699 0.01069959 0.00663627 ... 0.00709241 0.01170715 0.0083324 ]\n  [0.00680568 0.01763043 0.01094075 ... 0.01005474 0.01359353 0.0070264 ]]\n\n [[0.00560598 0.01862064 0.00643899 ... 0.01564105 0.00751078 0.01364231]\n  [0.00730061 0.01720654 0.00569534 ... 0.00774755 0.01834954 0.01045312]\n  [0.01243223 0.01369837 0.00852198 ... 0.00909312 0.01128154 0.0063348 ]\n  [0.00629803 0.02141227 0.00831497 ... 0.00662649 0.02291891 0.0074902 ]\n  [0.01139779 0.01380648 0.01799767 ... 0.00533533 0.01638228 0.00993858]\n  [0.00746125 0.00976811 0.01449763 ... 0.00673519 0.01113056 0.00573259]]\n\n [[0.00866404 0.0106354  0.00790299 ... 0.00938455 0.00953305 0.00871722]\n  [0.0067823  0.01704649 0.00853296 ... 0.00961295 0.00982589 0.01174172]\n  [0.00463716 0.02216605 0.00772885 ... 0.00809792 0.00928158 0.0097446 ]\n  [0.00792143 0.02060956 0.01374969 ... 0.00686169 0.01472474 0.00934699]\n  [0.00460164 0.01596515 0.01950155 ... 0.0045944  0.01449619 0.0141474 ]\n  [0.00820918 0.01899235 0.00893106 ... 0.00505789 0.01207003 0.01020742]]].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4478/515446942.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md_acc_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_acc_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4478/307214827.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, epochs, batch_size, n_eval)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# iterate over the dataset and update the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgan_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;31m# update discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0md_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    771\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32), but the yielded element was [[[0.00784405 0.01363464 0.00795084 ... 0.00616735 0.01232874 0.00930799]\n  [0.00743604 0.01299697 0.00657471 ... 0.00857116 0.01247007 0.01078571]\n  [0.00660481 0.00816573 0.00864302 ... 0.00780875 0.01493056 0.01225976]\n  [0.01089922 0.00896515 0.0062316  ... 0.00620996 0.0120111  0.00710753]\n  [0.00853574 0.0143795  0.0166215  ... 0.00633353 0.01574256 0.00595049]\n  [0.01126612 0.01166151 0.00304855 ... 0.00881959 0.0092577  0.00451845]]\n\n [[0.00901932 0.01744283 0.0126614  ... 0.0051707  0.0067511  0.01264073]\n  [0.00937799 0.01681233 0.00838365 ... 0.00519401 0.01234819 0.00877401]\n  [0.01010063 0.01713853 0.00942147 ... 0.00670861 0.01917028 0.0098217 ]\n  [0.00698665 0.01906229 0.00689812 ... 0.00844652 0.00837909 0.00722283]\n  [0.00642558 0.00801662 0.00641306 ... 0.00865609 0.00958089 0.0129503 ]\n  [0.012514   0.00982862 0.00653447 ... 0.01629108 0.00858043 0.01294903]]\n\n [[0.01168932 0.01072754 0.00446282 ... 0.01017345 0.01357007 0.0075546 ]\n  [0.00711788 0.02343464 0.00823045 ... 0.00713765 0.01143885 0.00887725]\n  [0.00726337 0.01336324 0.01039504 ... 0.00479237 0.01452046 0.01611213]\n  [0.00844331 0.01957811 0.00758222 ... 0.00822655 0.01099372 0.00893688]\n  [0.01294964 0.01274304 0.00759487 ... 0.01699475 0.01217456 0.00511607]\n  [0.01069593 0.00999451 0.01246619 ... 0.01275391 0.00916322 0.01002251]]\n\n ...\n\n [[0.0071698  0.01665911 0.01019003 ... 0.00534528 0.01018087 0.00948511]\n  [0.00602717 0.01360997 0.0104102  ... 0.00674121 0.00906293 0.01796024]\n  [0.00478603 0.0110727  0.00610275 ... 0.00517731 0.01377118 0.01704021]\n  [0.00670524 0.01187402 0.00813616 ... 0.01004024 0.01256021 0.01039293]\n  [0.00617699 0.01069959 0.00663627 ... 0.00709241 0.01170715 0.0083324 ]\n  [0.00680568 0.01763043 0.01094075 ... 0.01005474 0.01359353 0.0070264 ]]\n\n [[0.00560598 0.01862064 0.00643899 ... 0.01564105 0.00751078 0.01364231]\n  [0.00730061 0.01720654 0.00569534 ... 0.00774755 0.01834954 0.01045312]\n  [0.01243223 0.01369837 0.00852198 ... 0.00909312 0.01128154 0.0063348 ]\n  [0.00629803 0.02141227 0.00831497 ... 0.00662649 0.02291891 0.0074902 ]\n  [0.01139779 0.01380648 0.01799767 ... 0.00533533 0.01638228 0.00993858]\n  [0.00746125 0.00976811 0.01449763 ... 0.00673519 0.01113056 0.00573259]]\n\n [[0.00866404 0.0106354  0.00790299 ... 0.00938455 0.00953305 0.00871722]\n  [0.0067823  0.01704649 0.00853296 ... 0.00961295 0.00982589 0.01174172]\n  [0.00463716 0.02216605 0.00772885 ... 0.00809792 0.00928158 0.0097446 ]\n  [0.00792143 0.02060956 0.01374969 ... 0.00686169 0.01472474 0.00934699]\n  [0.00460164 0.01596515 0.01950155 ... 0.0045944  0.01449619 0.0141474 ]\n  [0.00820918 0.01899235 0.00893106 ... 0.00505789 0.01207003 0.01020742]]].\nTraceback (most recent call last):\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1045, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'ndarray'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1047, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32), but the yielded element was [[[0.00784405 0.01363464 0.00795084 ... 0.00616735 0.01232874 0.00930799]\n  [0.00743604 0.01299697 0.00657471 ... 0.00857116 0.01247007 0.01078571]\n  [0.00660481 0.00816573 0.00864302 ... 0.00780875 0.01493056 0.01225976]\n  [0.01089922 0.00896515 0.0062316  ... 0.00620996 0.0120111  0.00710753]\n  [0.00853574 0.0143795  0.0166215  ... 0.00633353 0.01574256 0.00595049]\n  [0.01126612 0.01166151 0.00304855 ... 0.00881959 0.0092577  0.00451845]]\n\n [[0.00901932 0.01744283 0.0126614  ... 0.0051707  0.0067511  0.01264073]\n  [0.00937799 0.01681233 0.00838365 ... 0.00519401 0.01234819 0.00877401]\n  [0.01010063 0.01713853 0.00942147 ... 0.00670861 0.01917028 0.0098217 ]\n  [0.00698665 0.01906229 0.00689812 ... 0.00844652 0.00837909 0.00722283]\n  [0.00642558 0.00801662 0.00641306 ... 0.00865609 0.00958089 0.0129503 ]\n  [0.012514   0.00982862 0.00653447 ... 0.01629108 0.00858043 0.01294903]]\n\n [[0.01168932 0.01072754 0.00446282 ... 0.01017345 0.01357007 0.0075546 ]\n  [0.00711788 0.02343464 0.00823045 ... 0.00713765 0.01143885 0.00887725]\n  [0.00726337 0.01336324 0.01039504 ... 0.00479237 0.01452046 0.01611213]\n  [0.00844331 0.01957811 0.00758222 ... 0.00822655 0.01099372 0.00893688]\n  [0.01294964 0.01274304 0.00759487 ... 0.01699475 0.01217456 0.00511607]\n  [0.01069593 0.00999451 0.01246619 ... 0.01275391 0.00916322 0.01002251]]\n\n ...\n\n [[0.0071698  0.01665911 0.01019003 ... 0.00534528 0.01018087 0.00948511]\n  [0.00602717 0.01360997 0.0104102  ... 0.00674121 0.00906293 0.01796024]\n  [0.00478603 0.0110727  0.00610275 ... 0.00517731 0.01377118 0.01704021]\n  [0.00670524 0.01187402 0.00813616 ... 0.01004024 0.01256021 0.01039293]\n  [0.00617699 0.01069959 0.00663627 ... 0.00709241 0.01170715 0.0083324 ]\n  [0.00680568 0.01763043 0.01094075 ... 0.01005474 0.01359353 0.0070264 ]]\n\n [[0.00560598 0.01862064 0.00643899 ... 0.01564105 0.00751078 0.01364231]\n  [0.00730061 0.01720654 0.00569534 ... 0.00774755 0.01834954 0.01045312]\n  [0.01243223 0.01369837 0.00852198 ... 0.00909312 0.01128154 0.0063348 ]\n  [0.00629803 0.02141227 0.00831497 ... 0.00662649 0.02291891 0.0074902 ]\n  [0.01139779 0.01380648 0.01799767 ... 0.00533533 0.01638228 0.00993858]\n  [0.00746125 0.00976811 0.01449763 ... 0.00673519 0.01113056 0.00573259]]\n\n [[0.00866404 0.0106354  0.00790299 ... 0.00938455 0.00953305 0.00871722]\n  [0.0067823  0.01704649 0.00853296 ... 0.00961295 0.00982589 0.01174172]\n  [0.00463716 0.02216605 0.00772885 ... 0.00809792 0.00928158 0.0097446 ]\n  [0.00792143 0.02060956 0.01374969 ... 0.00686169 0.01472474 0.00934699]\n  [0.00460164 0.01596515 0.01950155 ... 0.0045944  0.01449619 0.0141474 ]\n  [0.00820918 0.01899235 0.00893106 ... 0.00505789 0.01207003 0.01020742]]].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "epochs = 101\n",
    "d_acc_history, d_loss_history, g_acc_history, g_loss_history = train(generator, discriminator, gan, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db84c0-205d-48e6-8cb0-9eed0fca944d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(range(1, epochs + 1), d_loss_history, label='Discriminator Loss')\n",
    "ax1.plot(range(1, epochs + 1), g_loss_history, label='Generator Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(1, epochs + 1), d_acc_history, label='Discriminator Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4b995-caab-4e73-9b5a-752cd170f276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1ae20-85d4-4ada-ab51-c5ed09ccf502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06485880-166d-4d86-8584-c17036bcc3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
