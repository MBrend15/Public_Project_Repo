{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4d9ebd-ce9a-4150-8fc4-cbe0a4eecc31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-88250bdb-5956-4aa5-a458-3fa757fcd90a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 130ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-88250bdb-5956-4aa5-a458-3fa757fcd90a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/6ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 03:40:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 03:40:46 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f752d7-2f69-493b-a03a-0acb4db74db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295239d-3d08-4f7d-bef1-1de64e1d0b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64fc124-d080-4ff2-8c79-9918822704ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ds = spark.read.parquet(*[\"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep3/*\"]) \\\n",
    "                .withColumn(\"event_sequence\",col('event_sequence').cast('string')) \\\n",
    "                .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64e704df-8177-4e3d-8436-16f3e46e533c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tot = ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20dd31f-3f4c-4b1d-9213-29859381e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------------+\n",
      "|mal_trace|cnt_per_group|perc_of_count_total|\n",
      "+---------+-------------+-------------------+\n",
      "|        1|       118763| 0.6835843967111419|\n",
      "|        0|     17254805|  99.31641560328886|\n",
      "+---------+-------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ds.groupBy(\"mal_trace\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'cnt_per_group') \\\n",
    "    .withColumn('perc_of_count_total', (col('cnt_per_group') / tot) * 100 ) \\\n",
    "    .sort(\"perc_of_count_total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51475f9f-73c6-477b-a45e-d3f76a3d4d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 6\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "num_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d53c55-83ec-4b3f-929b-dc66f0fb3a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb58e17-1e00-4ad8-a799-9a6d250f6597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ds_events = ds.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992eb682-a6c9-490c-8426-46248ea03038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9cc65-f4eb-4612-b0c2-ec4d4e640779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get vocab for full dataset \n",
    "tokenizer.fit_on_texts(ds_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504683e-0e1b-43ac-bb24-eb36db222491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get only malicious data\n",
    "ds_mal = ds.filter( col('mal_trace') == 1).cache()\n",
    "ds_mal = ds_mal.limit(num_samples).cache()\n",
    "ds.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172993cb-509d-4684-95da-b009d1eecde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm_events = ds_mal.select('event_sequence').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbefcd-dc85-4baa-b7bc-8bbe4b20eb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm_labels = ds_mal.select('mal_trace').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f64c30-5706-4ff5-b2e9-13610902d003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "vocab_count = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd067533-4120-48d6-b2be-44bc160470fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c7a56-505d-4d73-84f7-13c116291646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one hot encode the data\n",
    "dm_sequences = tokenizer.texts_to_sequences(dm_events)\n",
    "dm_padded = tf.keras.utils.pad_sequences(dm_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "seq_enc_tensor = tf.one_hot(dm_padded, vocab_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d9a6c-c137-4194-bed7-a5e1beb27c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_mal.select('event_sequence').limit(1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14821ad4-6aee-4d1c-9f73-9ed40bde1a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8916a0-1b14-4dd1-9554-e3bfceb6bfb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13ccb8-4878-4a18-8d6b-523d98960f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842ecdb-06a1-4469-85bd-91dc0059f1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_enc_tensor.shape\n",
    "# shape - (input_len, sequence_length, vocab_size)\n",
    "input_len = seq_enc_tensor.shape[0]\n",
    "sequence_length = seq_enc_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b6f5d-1ae6-4632-8570-8b0751b5f695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_count, activation='softmax')),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "            tf.keras.layers.LSTM(128, return_sequences=False),\n",
    "            tf.keras.layers.Dense(2, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, sequence_length, vocab_count], minval=1, maxval=vocab_count, dtype=tf.int32)\n",
    "    return n\n",
    "\n",
    "def generate_fake_samples(generator):\n",
    "    # generate points in latent space & pass through generator\n",
    "    x = generator.predict(generate_latent_space(), verbose=0)\n",
    "    # create class labels\n",
    "    y = zeros((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def generate_real_samples():\n",
    "    x = seq_enc_tensor\n",
    "    # create class labels\n",
    "    y = ones((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def train(g_model, d_model, gan_model, epochs=5, n_eval=20):\n",
    "    d_acc_history = []\n",
    "    d_loss_history = []\n",
    "    g_acc_history = []\n",
    "    g_loss_history = []\n",
    "\n",
    "    d_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    g_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_real_samples()\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model)\n",
    "\n",
    "        # update discriminator\n",
    "        d_real_loss = d_model.train_on_batch(x_real, y_real)\n",
    "        d_fake_loss = d_model.train_on_batch(x_fake, y_fake)\n",
    "        d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "\n",
    "        d_real_pred = d_model.predict_on_batch(x_real)\n",
    "        d_fake_pred = d_model.predict_on_batch(x_fake)\n",
    "\n",
    "        d_metric.update_state(tf.concat([y_real, y_fake], axis=0), tf.concat([d_real_pred, d_fake_pred], axis=0))\n",
    "        d_acc = d_metric.result().numpy()\n",
    "\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        y_gan = ones((input_len, 1))\n",
    "        g_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_pred = gan_model.predict_on_batch(x_gan)\n",
    "        g_metric.update_state(tf.one_hot(tf.cast(y_gan, tf.int32), depth=2), gan_pred)\n",
    "        g_acc = g_metric.result().numpy()\n",
    "\n",
    "        d_acc_history.append(d_acc)\n",
    "        d_loss_history.append(d_loss)\n",
    "        g_acc_history.append(g_acc)\n",
    "        g_loss_history.append(g_loss)\n",
    "\n",
    "        if i % n_eval == 0:\n",
    "            print(f\"Epoch {i}: Discriminator Loss: {d_loss}, Discriminator Accuracy: {d_acc}, Generator Loss: {g_loss}, Generator Accuracy: {g_acc}\")\n",
    "\n",
    "    return d_acc_history, d_loss_history, g_acc_history, g_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2bc25-832b-4b86-bf51-609dde91aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4068c3-bd4a-4228-9991-43cbdb8fce24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = define_generator()\n",
    "discriminator = define_discriminator()\n",
    "gan = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab7c04-e0cd-4e7e-9226-43ac91672f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 180\n",
    "d_acc_history, d_loss_history, g_acc_history, g_loss_history = train(generator, discriminator, gan, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db84c0-205d-48e6-8cb0-9eed0fca944d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(range(1, epochs + 1), d_loss_history, label='Discriminator Loss')\n",
    "ax1.plot(range(1, epochs + 1), g_loss_history, label='Generator Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(1, epochs + 1), d_acc_history, label='Discriminator Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4b995-caab-4e73-9b5a-752cd170f276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1ae20-85d4-4ada-ab51-c5ed09ccf502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06485880-166d-4d86-8584-c17036bcc3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeff66a-b0b6-47d9-b54a-601d60790fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccaa0fd-e3db-4baa-810a-8d58f48e42b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1cee6-656a-404b-9e8b-e86b350bea91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_gen, y_gen = generate_fake_samples(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3d2f2-12df-4190-932c-41b3a8670328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_seq_enc = tf.argmax(x_gen, axis=-1)\n",
    "new_seq_texts = tokenizer.sequences_to_texts(new_seq_enc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9823c8-30b3-4a21-909e-4ab7fa748999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = new_seq_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f50f4f-6578-4e2d-9598-b6d9eb932f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len('10000000000100001000100001000000000000010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a3f72-a6fc-4db8-bfc0-818796635b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_events = [[','.join(n.split())] for n in new_seq_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c8961-e694-45cf-9bfc-2bde0bd00c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178337c-32dd-435a-a1a5-431807cd06db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_labels = [1]*input_len\n",
    "trace_list = [99999]*input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971397c-cd32-44c0-bd79-f65522cd304b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_mal.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e0a23-dc18-4be6-a2fe-7bc3d9df4d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_gen = list(zip(trace_list, gen_labels, gen_labels, gen_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d55ccb-378a-4660-bb38-2b7264e06e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_gen = spark.createDataFrame(d_gen, ['Trace', 'mal_trace', 'malicious', 'event_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07577f-c420-4f3a-9b78-f8656efe1f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aee1f3-7a5a-4ede-a40c-dd5d6c2daac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_gen.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6e83f-bc9e-4eaf-a91c-edf6370c2210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_gen.groupBy(\"mal_trace\").agg(countDistinct('event_sequence')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980268a0-2639-4a0f-aedd-11a2434d985c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_mal.groupBy(\"mal_trace\").agg(countDistinct('event_sequence')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f702f0e-bf8f-49d6-9850-17f7cfcb86fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_gen.write.option(\"maxRecordsPerFile\", 300000).mode(\"overwrite\").parquet(\"s3a://sapient-bucket-trusted/prod/graph/motifs/gen_malicious/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
