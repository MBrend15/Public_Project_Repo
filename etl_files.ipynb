{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970130b0-b08c-4536-936e-ca923cc595a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setup based on this: https://t-redactyl.io/blog/2020/08/reading-s3-data-into-a-spark-dataframe-using-sagemaker.html\n",
    "import boto3\n",
    "import json \n",
    "import time\n",
    "import pandas as pd\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker_pyspark\n",
    "import botocore.session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ef5d6-368f-43af-b519-ba5112c87b79",
   "metadata": {},
   "source": [
    "## Set Spark Session Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8e9008-6651-4c17-8c12-eef2b18e10fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = botocore.session.get_session()\n",
    "credentials = session.get_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7486ea00-f477-4f51-bf6e-b66a57f1a557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = boto3.client('secretsmanager')\n",
    "response = client.get_secret_value(\n",
    "    SecretId='sapient-s3-access'\n",
    ")\n",
    "response = json.loads(response['SecretString'])\n",
    "access_key = response[\"aws_access_key_id\"]\n",
    "secret_key = response[\"aws_secret_access_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372553c2-9f17-4c4f-b253-275e30a1ef35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf()\n",
    "        .set(\"spark.driver.extraClassPath\", \":\".join(sagemaker_pyspark.classpath_jars()))\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9392e443-f6d6-4a54-bbb8-2972eafaf97e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/04 00:43:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/04 00:43:27 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/03/04 00:43:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/03/04 00:43:29 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# https://spark.apache.org/docs/latest/configuration.html#memory-management\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(conf=conf) \\\n",
    "    .config('fs.s3a.access.key', access_key)\n",
    "    .config('fs.s3a.secret.key', secret_key)\n",
    "    .config('spark.network.timeout', 300)\n",
    "    .config('spark.local.dir', '/home/ec2-user/SageMaker/tmp')\n",
    "    .config(\"spark.executor.memory\", \"70g\")\n",
    "    .config(\"spark.driver.memory\", \"50g\")\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\")\n",
    "    .config(\"spark.memory.offHeap.size\",\"50g\")\n",
    "    .appName(\"sapient\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f0acc-5281-4b73-a33b-67ac7c05b96a",
   "metadata": {},
   "source": [
    "## Functions to Load and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5e8ea5-b6a8-4fdd-84d5-22e3b31c7340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read from raw bucket + write to refined bucket + aggregate final to the trusted bucket\n",
    "s3_url_raw = \"s3a://sapient-bucket-raw/\"\n",
    "s3_url_refined = \"s3a://sapient-bucket-refined/\"\n",
    "s3_url_trusted = \"s3a://sapient-bucket-trusted/\"\n",
    "bro_cols_conn = ['ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_', 'id.resp_p', 'proto', 'service', 'duration', 'orig_bytes', 'resp_bytes', 'conn_state', \n",
    "                 'local_orig', 'local_resp', 'missed_bytes', 'history', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'tunnel_parents']\n",
    "bro_cols_rep = ['ts', 'level', 'message', 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad42778-7a18-4857-a75a-91f383bfa81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# schemas to reduce read times for spark \n",
    "bro_schema = StructType([\n",
    "        StructField('ts', StringType(), True),\n",
    "        StructField('uid', StringType(), True),\n",
    "        StructField('id.orig_h', StringType(), True),\n",
    "        StructField('id.orig_p', IntegerType(), True),\n",
    "        StructField('id.resp_', StringType(), True),\n",
    "        StructField('id.resp_p', IntegerType(), True),\n",
    "        StructField('proto', StringType(), True),\n",
    "        StructField('service', StringType(), True),\n",
    "        StructField('duration', StringType(), True),\n",
    "        StructField('orig_bytes', IntegerType(), True),\n",
    "        StructField('resp_bytes', IntegerType(), True),\n",
    "        StructField('conn_state', StringType(), True),\n",
    "        StructField('local_orig', StringType(), True),\n",
    "        StructField('local_resp', StringType(), True),\n",
    "        StructField('missed_bytes', IntegerType(), True),\n",
    "        StructField('history', StringType(), True),\n",
    "        StructField('orig_pkts', IntegerType(), True),\n",
    "        StructField('orig_ip_bytes', IntegerType(), True),\n",
    "        StructField('resp_pkts', IntegerType(), True),\n",
    "        StructField('resp_ip_bytes', IntegerType(), True),\n",
    "        StructField('tunnel_parents', StringType(), True)\n",
    "    ])\n",
    "\n",
    "ecar_bro_schema = StructType([\n",
    "        StructField('action', StringType(), True),\n",
    "        StructField('actorID', StringType(), True),\n",
    "        StructField('hostname', StringType(), True),\n",
    "        StructField('id', StringType(), True),\n",
    "        StructField('object', StringType(), True),\n",
    "        StructField('objectID', StringType(), True),\n",
    "        StructField('pid', IntegerType(), True),\n",
    "        StructField('ppid', IntegerType(), True),\n",
    "        StructField('principal', StringType(), True),\n",
    "        StructField('properties', StructType([\n",
    "            StructField('acuity_level', StringType(), True),\n",
    "            StructField('bro_uid', StringType(), True),\n",
    "            StructField('dest_ip', StringType(), True),\n",
    "            StructField('dest_port', IntegerType(), True),\n",
    "            StructField('direction', StringType(), True),\n",
    "            StructField('image_path', StringType(), True),\n",
    "            StructField('l4protocol', StringType(), True),\n",
    "            StructField('src_ip', StringType(), True),\n",
    "            StructField('src_port', IntegerType(), True),\n",
    "            ])),\n",
    "        StructField('tid', IntegerType(), True),\n",
    "        StructField('timestamp', TimestampType(), True)\n",
    "    ])\n",
    "\n",
    "ecar_schema = StructType([\n",
    "        StructField('action', StringType(), True),\n",
    "        StructField('actorID', StringType(), True),\n",
    "        StructField('hostname', StringType(), True),\n",
    "        StructField('id', StringType(), True),\n",
    "        StructField('object', StringType(), True),\n",
    "        StructField('objectID', StringType(), True),\n",
    "        StructField('pid', IntegerType(), True),\n",
    "        StructField('ppid', IntegerType(), True),\n",
    "        StructField('principal', StringType(), True),\n",
    "        StructField('properties', StructType([\n",
    "            StructField('acuity_level', StringType(), True),\n",
    "            StructField('base_address', StringType(), True),\n",
    "            StructField('command_line', StringType(), True),\n",
    "            StructField('context_info', StringType(), True),\n",
    "            StructField('data', StringType(), True),\n",
    "            StructField('dest_port', IntegerType(), True),\n",
    "            StructField('direction', StringType(), True),\n",
    "            StructField('end_time', TimestampType(), True),\n",
    "            StructField('file_path', StringType(), True),\n",
    "            StructField('image_path', StringType(), True),\n",
    "            StructField('info_class', StringType(), True),\n",
    "            StructField('key', StringType(), True),\n",
    "            StructField('l4protocol', StringType(), True),\n",
    "            StructField('logon_id', StringType(), True),\n",
    "            StructField('module_path', StringType(), True),\n",
    "            StructField('new_path', StringType(), True),\n",
    "            StructField('parent_image_path', StringType(), True),\n",
    "            StructField('path', StringType(), True),\n",
    "            StructField('payload', StringType(), True),\n",
    "            StructField('privileges', StringType(), True),\n",
    "            StructField('requesting_domain', StringType(), True),\n",
    "            StructField('requesting_logon_id', StringType(), True),\n",
    "            StructField('requesting_user', StringType(), True),\n",
    "            StructField('sid', StringType(), True),\n",
    "            StructField('size', StringType(), True),\n",
    "            StructField('src_ip', StringType(), True),\n",
    "            StructField('src_pid', IntegerType(), True),\n",
    "            StructField('src_port', IntegerType(), True),\n",
    "            StructField('src_tid', StringType(), True),\n",
    "            StructField('stack_base', StringType(), True),\n",
    "            StructField('stack_limit', StringType(), True),\n",
    "            StructField('start_address', StringType(), True),\n",
    "            StructField('start_time', TimestampType(), True),\n",
    "            StructField('subprocess_tag', StringType(), True),\n",
    "            StructField('task_name', StringType(), True),\n",
    "            StructField('task_pid', IntegerType(), True),\n",
    "            StructField('task_process_uuid', StringType(), True),\n",
    "            StructField('tgt_pid', IntegerType(), True),\n",
    "            StructField('tgt_pid_uuid', StringType(), True),\n",
    "            StructField('tgt_tid', IntegerType(), True),\n",
    "            StructField('type', StringType(), True),\n",
    "            StructField('user', StringType(), True),\n",
    "            StructField('user_name', StringType(), True),\n",
    "            StructField('user_stack_base', StringType(), True),\n",
    "            StructField('user_stack_limit', StringType(), True),\n",
    "            StructField('value', StringType(), True)\n",
    "            ])),\n",
    "        StructField('tid', IntegerType(), True),\n",
    "        StructField('timestamp', TimestampType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcc137e-74bf-4490-b0ac-4460fbefb212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ecar_files():\n",
    "    env = 'prod'\n",
    "    type = 'car'\n",
    "    paths=['23Sep19-red',\n",
    "           '24Sep19',\n",
    "           '25Sep'\n",
    "          ]\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket = 'sapient-bucket-raw',\n",
    "        Prefix = f'{env}/')\n",
    "\n",
    "    all_files = []\n",
    "    for p in paths:\n",
    "        files = []\n",
    "        for content in response.get('Contents', []):\n",
    "            files.append(content['Key'])\n",
    "        files = [f\"{s3_url_raw}/\" + f for f in files if p in f]\n",
    "        all_files = all_files + files\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948047f5-3308-49ad-b9c7-f281aabb8c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loadAndCheckpoint(type='ecar-bro', env='prod', size='small'):\n",
    "    \"\"\"\n",
    "    type: ecar, ecar-bro, bro, labels\n",
    "    This function reads a file from json or log text and writes it as a parquet.\n",
    "    \"\"\"\n",
    "    ecar_fil = [(\"FLOW\"), (\"PROCESS\"), (\"FILE\"),(\"SHELL\")]\n",
    "    if size == 'small':\n",
    "        # 1 million\n",
    "        read_lim = 1000000\n",
    "    elif size == 'medium':\n",
    "        # 100 million\n",
    "        read_lim = 100000000\n",
    "    elif size == 'large':\n",
    "        # 1 billion\n",
    "        read_lim = 1000000000  \n",
    "    elif size == 'all':\n",
    "        # 1 billion\n",
    "        read_lim = 'all' \n",
    "    start_time = time.time()\n",
    "    if type in ('ecar', 'car'):\n",
    "        if env == 'prod':\n",
    "            ecar_files = get_ecar_files()\n",
    "                #TODO: new filter for time\n",
    "            df = spark.read.schema(ecar_schema).json(ecar_files).filter(col(\"object\").isin(ecar_fil) & \n",
    "                                                                       (dayofmonth(col('timestamp')) == 23)).cache()\n",
    "        else:\n",
    "            df = spark.read.schema(ecar_schema).json(f\"{s3_url_raw}/{env}/{type}/**/**/**/*.json\").filter(col(\"object\").isin(ecar_fil)).cache()\n",
    "        if size == 'all':\n",
    "            pass\n",
    "        else: \n",
    "            df = df.limit(read_lim)\n",
    "        print(time.strftime('%l:%M%p %Z on %b %d, %Y') + \" -- read time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        #print(time.strftime('%l:%M%p %Z on %b %d, %Y') + f\" -- Your new dataframe has {df.count():,} rows.\")\n",
    "        start_time = time.time()\n",
    "        df = df.select(*df.columns, \"properties.*\").drop('properties')\n",
    "        df = df.withColumn('event_minute', minute(col('timestamp'))) \\\n",
    "               .withColumn('event_day', dayofmonth(col('timestamp'))) \\\n",
    "               .withColumn('event_hour', hour(col('timestamp')))\n",
    "        print(time.strftime('%l:%M%p %Z on %b %d, %Y') + \" -- schema expansion time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "        # numPartitions = 16000\n",
    "        # df = df.repartition(numPartitions)\n",
    "        df.write.option(\"maxRecordsPerFile\", 300000).mode(\"overwrite\").partitionBy(\"event_day\", \"event_hour\", \"event_minute\").parquet(f\"{s3_url_refined}/{env}/ecar/{size}\")\n",
    "    elif type in ('ecar-bro','car-bro'):\n",
    "        df = spark.read.schema(ecar_bro_schema).json(f\"{s3_url_raw}/{env}/{type}/**/**/**/*.json\").cache()\n",
    "        # this will extract and flatten nested properties column\n",
    "        if size == 'all':\n",
    "            pass\n",
    "        else: \n",
    "            df = df.limit(read_lim)\n",
    "        print(time.strftime('%l:%M%p %Z on %b %d, %Y') + \" -- read time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        #print(time.strftime('%l:%M%p %Z on %b %d, %Y') + f\" -- Your new dataframe has {df.count():,} rows.\")\n",
    "        start_time = time.time()\n",
    "        df = df.select(*df.columns, \"properties.*\").drop('properties')\n",
    "        df = df.withColumn('event_minute', minute(col('timestamp'))) \\\n",
    "               .withColumn('event_day', dayofmonth(col('timestamp'))) \\\n",
    "               .withColumn('event_hour', hour(col('timestamp')))\n",
    "        df.write.option(\"maxRecordsPerFile\", 300000).mode(\"overwrite\").partitionBy(\"event_day\", \"event_hour\").parquet(f\"{s3_url_refined}/{env}/ecar-bro/{size}\")\n",
    "    elif type == 'bro':\n",
    "        df = spark.read.schema(bro_schema).csv(f\"{s3_url_raw}/{env}/**/**/conn*.log\", sep=\"\\t\", comment=\"#\", header=False).cache()\n",
    "        if size == 'all':\n",
    "            pass\n",
    "        else: \n",
    "            df = df.limit(read_lim)\n",
    "        df = df.toDF(*bro_cols_conn)\n",
    "        print(time.strftime('%l:%M%p %Z on %b %d, %Y') + \" -- read time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        #print(time.strftime('%l:%M%p %Z on %b %d, %Y') + f\" -- Your new dataframe has {df.count():,} rows.\")\n",
    "        start_time = time.time()\n",
    "        df.write.option(\"maxRecordsPerFile\", 300000).mode(\"overwrite\").parquet(f\"{s3_url_refined}/{env}/bro/{size}\")\n",
    "    elif type == 'labels':\n",
    "        df = spark.read.csv(f\"{s3_url_raw}/{type}/*.csv\", sep=\",\", header=True).cache()\n",
    "        df.write.option(\"maxRecordsPerFile\", 300000).mode(\"overwrite\").parquet(f\"{s3_url_refined}/{env}/labels\")\n",
    "    print(time.strftime('%l:%M%p %Z on %b %d, %Y') + \" -- write time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ee57e1-0d17-4b96-bdc9-ce32d2d2e9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env='prod'\n",
    "size='small'\n",
    "# this is here because the prod ecar/ecar-bro are missing the \"e\"s and is a short term fix\n",
    "if env == 'prod':\n",
    "    ftype = 'car'\n",
    "else:\n",
    "    ftype = 'ecar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67421342-44e1-4e5a-a095-895a5e69be39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd29748c-11a0-453d-9773-2578a7b2a6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write time: --- 9.058502435684204 seconds ---\n"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint('labels', env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c06e2-aefa-49e7-b8f3-f3b7a72b116b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa96722-457e-4ccb-a7fd-3858e33acd04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read time: --- 9.37377119064331 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write time: --- 153.34089350700378 seconds ---\n"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}-bro', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e63d8a17-0c40-49ce-b71b-81429239956f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:44AM UTC on Mar 04, 2023 -- read time: --- 14.87155532836914 seconds ---\n",
      "12:44AM UTC on Mar 04, 2023 -- schema expansion time: --- 0.4012305736541748 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.                    (19 + 4) / 13021]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o101.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloadAndCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mftype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m, in \u001b[0;36mloadAndCheckpoint\u001b[0;34m(type, env, size)\u001b[0m\n\u001b[1;32m     40\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# numPartitions = 16000\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# df = df.repartition(numPartitions)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxRecordsPerFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartitionBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent_day\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent_hour\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent_minute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ms3_url_refined\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43menv\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/ecar/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecar-bro\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcar-bro\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     45\u001b[0m     df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mschema(ecar_bro_schema)\u001b[38;5;241m.\u001b[39mjson(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_url_raw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/**/**/**/*.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcache()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1140\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o101.parquet"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670f8f8-3d2b-41a0-a899-ab92c4d4656b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6580eb82-aba7-41cb-9a7b-85cbe0149014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size='medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "836379b5-2f93-47f8-86a4-814b5da767b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read time: --- 3.033254861831665 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write time: --- 725.4632656574249 seconds ---\n"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}-bro', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dcdda15-61ac-4270-81b1-8330478c3d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read time: --- 0.5497806072235107 seconds ---\n",
      "schema expansion time: --- 0.06387162208557129 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write time: --- 2129.4056890010834 seconds ---\n"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f552b78-75d3-4f41-bbd1-2083e9a5f6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c98ca7bc-2556-42e6-932f-c12a45afa318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size='large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4d1c44-cbfb-4aa3-bd46-eee8dddb9fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read time: --- 3.0137670040130615 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write time: --- 752.6250596046448 seconds ---\n"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}-bro', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfa18d64-c723-4858-a8c3-47052a95bef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read time: --- 0.584460973739624 seconds ---\n",
      "schema expansion time: --- 0.06183433532714844 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write time: --- 10365.53863453865 seconds ---\n"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211f3bf-4ad5-428a-a35c-cce2027bd6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f0383b-0b0b-4855-9a18-2973f0ccad29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1e80acd-5017-4da8-b8ca-add84482f261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read time: --- 2.7087810039520264 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write time: --- 2072.032541513443 seconds ---\n"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}-bro', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34201f-c7de-4d7e-ade7-e9de5adfb0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5:32AM UTC on Feb 28, 2023 -- read time: --- 7.466861724853516 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5:32AM UTC on Feb 28, 2023 -- Your new dataframe has 2,898,070,614 rows.\n",
      " 6:13AM UTC on Feb 28, 2023 -- schema expansion time: --- 0.15707945823669434 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "loadAndCheckpoint(f'{ftype}', env=env, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3ff6e-579e-48bf-b06c-dabfecd21e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ef09f-1bd6-4d13-bed6-6fd5cd9a3cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
