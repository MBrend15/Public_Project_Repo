{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c33cce-a25f-4bc3-9742-e31e262f8612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "#from graphframes import GraphFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8989b370-d01d-4dab-a68c-5146469dcb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to generate a graphframe\n",
    "def create_graph(df):\n",
    "    #create trace matrix from malicious events for speed. \n",
    "    # Create distinct vertices with source as actorid, destination as objectid for malicious\n",
    "    src_vertices = df.selectExpr('actorID as id').distinct()\n",
    "    dst_vertices = df.selectExpr('objectID as id').distinct()\n",
    "    vertices = src_vertices.union(dst_vertices).distinct()\n",
    "\n",
    "    # Create edges by using timestamp as an edge\n",
    "    edges = df.selectExpr('actorID as src', 'objectID as dst', 'timestamp', 'object', 'action', 'hostname', 'user_name', 'privileges', 'image_path',\n",
    "                          'parent_image_path', 'new_path', 'file_path', 'direction', 'logon_id', 'requesting_domain', 'requesting_user', 'malicious')\n",
    "\n",
    "    # Create GraphFrame\n",
    "    g = GraphFrame(vertices, edges)\n",
    "    motifs6 = g.find(\"(a)-[e1]->(b); (b)-[e2]->(c); (c)-[e3]->(d); (d)-[e4]->(e); (e)-[e5]->(f); (f)-[e6]->(g)\")\n",
    "\n",
    "    #create paths and count\n",
    "    # filter paths to only those where all edges are connected\n",
    "    connected_paths = motifs6.filter(\"e1.dst = e2.src and e2.dst = e3.src and e3.dst = e4.src and e4.dst = e5.src and e5.dst = e6.src\").cache()\n",
    "    print(\"event traces: \"+str(connected_paths.count()))\n",
    "    \n",
    "    return connected_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8d4d539-fe27-43fc-b80b-cb09a14eecf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to accept an event trace data frame and then encode it. Ideally we run this twice, once on the malicious\n",
    "#traces and again on benign traces. This implies that we run graphframes on both sets of events independently. \n",
    "\n",
    "#TODO: extract only the extensions, or declare file path an attribute \n",
    "\n",
    "def oneHotCol(df, colm, dict_mapping, cols_sparse):\n",
    "    \n",
    "    #now action\n",
    "    #turn into numeric index before encoding\n",
    "    \n",
    "    num = colm+'_numeric'\n",
    "    sparse = colm+'_sparse'\n",
    "    indexer = StringIndexer(inputCol=colm, outputCol=num, handleInvalid=\"keep\")\n",
    "    indexer_fitted = indexer.fit(df)\n",
    "    df_indexed = indexer_fitted.transform(df)\n",
    "\n",
    "    encoder = OneHotEncoder(inputCols=[num], outputCols=[sparse],dropLast=False)\n",
    "    df_onehot = encoder.fit(df_indexed).transform(df_indexed)\n",
    "    df_onehot = df_onehot.drop(colm, num)\n",
    "\n",
    "    #set dict to mapping\n",
    "    dict_mapping[colm] = indexer_fitted.labels\n",
    "    \n",
    "    #add column to cols_sparse list\n",
    "    cols_sparse.append(sparse)\n",
    "        \n",
    "    return df_onehot, dict_mapping, cols_sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14ee82f7-ed2f-4c4a-9745-ffbb59dfebc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#udf functions\n",
    "\n",
    "# define a user-defined function to convert binary int array to string array\n",
    "def binary_to_string_array(binary_int_array):\n",
    "    string_array = []\n",
    "    for i in binary_int_array:\n",
    "        string_array.append(str(int(i)))\n",
    "    return ''.join(string_array)\n",
    "\n",
    "# register the user-defined function as a UDF\n",
    "binary_to_string_array_udf = udf(binary_to_string_array, StringType())\n",
    "\n",
    "def int_cast(num):\n",
    "    return int(num)\n",
    "int_cast_udf = udf(int_cast, IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdc9b0de-18bc-40df-b302-a371021a11b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trace_encode(df, list_cols, output = 'ind'):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #step one accept the event trace transpose it, and explode it. \n",
    "\n",
    "    #add \"trace index\" to keep track of traces. important for transposing back\n",
    "    df_transp = df.withColumn(\"Trace\", (monotonically_increasing_id() + 1))\n",
    "    df_transp = df_transp.select(\"Trace\", \n",
    "                                 *[col for col in df_transp.columns if col != \"Trace\"])\n",
    "\n",
    "    #drop all vertices\n",
    "    df_transp = df_transp.drop('a','b','c','d','e','f','g')\n",
    "\n",
    "    #transpose rows \n",
    "    stacked_df = df_transp.selectExpr(\n",
    "        \"Trace\", \n",
    "        \"posexplode(array(e1, e2, e3, e4, e5, e6)) as (pos, col)\"\n",
    "    ).select(\n",
    "        \"Trace\", \n",
    "        expr('''CASE pos \n",
    "        WHEN 0 THEN 'e1' \n",
    "        WHEN 1 THEN 'e2'\n",
    "        WHEN 2 THEN 'e3'\n",
    "        WHEN 3 THEN 'e4'\n",
    "        WHEN 4 THEN 'e5'\n",
    "        ELSE 'e6' END''').alias(\"event\"),\n",
    "        \"col\"\n",
    "    ).orderBy(\"Trace\",\"event\")\n",
    "\n",
    "    #explode columns\n",
    "    df_onehot = stacked_df.select(*stacked_df.columns, \"col.*\").drop('col')\n",
    "    \n",
    "    #instantiate dictionary and return df\n",
    "    dict_mapping = {}\n",
    "    #list of sparse cols\n",
    "    list_sparse = []\n",
    "    \n",
    "    print(\"transposed explode: \"+ str(time.time() - start_time))\n",
    "    \n",
    "    #for all columns to one hot, one hot, preserve mapping\n",
    "    for colm in list_cols:\n",
    "        df_onehot, dict_mapping, list_sparse = oneHotCol(df_onehot,colm, dict_mapping, list_sparse)\n",
    "    \n",
    "    #assemble vectors for all sparse columns - this might be enough for our ML algorithms\n",
    "    assembler = VectorAssembler(inputCols=list_sparse, \n",
    "                            outputCol=\"final_vec\")\n",
    "    df_onehot = assembler.transform(df_onehot)\n",
    "    \n",
    "    \n",
    "    #turn into string\n",
    "    df_onehot = df_onehot.withColumn(\"vec2string\", binary_to_string_array_udf(\"final_vec\"))\n",
    "    \n",
    "    print(\"one-hot time: \"+ str(time.time() - start_time))\n",
    "    \n",
    "    \n",
    "    #now I need to arrange the output in a column-wise dataframe with event strings or indices and the malicious tag\n",
    "    if output == 'vec':\n",
    "        \n",
    "         #Generate a list of columns to drop\n",
    "        keep_cols = ['malicious','Trace','event','vec2string']\n",
    "        drop_cols = [col for col in df_onehot.columns  \n",
    "                     if col not in list_cols and col not in keep_cols]\n",
    "    \n",
    "        #i want to drop any columnn not in the column list or is the malicious column\n",
    "        df_onehot = df_onehot.drop(*drop_cols)\n",
    "        \n",
    "        #first pivot aka transpose and keep all events\n",
    "        pivot_vec = df_onehot.groupBy('Trace').pivot('event')\\\n",
    "        .agg(first('malicious'),first('vec2string'))\n",
    "        #then consolidate the columns into a single event sequence\n",
    "        df_onehot = pivot_vec.select('Trace',col('e1_first(malicious)').alias('malicious'),\n",
    "                                  array('e1_first(vec2string)', 'e2_first(vec2string)',\n",
    "                           'e3_first(vec2string)','e4_first(vec2string)', \n",
    "                           'e5_first(vec2string)', 'e6_first(vec2string)').alias('event_sequence'))\n",
    "    else: \n",
    "        \n",
    "        #index\n",
    "        indexer = StringIndexer(inputCol='vec2string', outputCol='event_ind')\n",
    "        indexer_fitted = indexer.fit(df_onehot)\n",
    "        df_onehot = indexer_fitted.transform(df_onehot)\n",
    "\n",
    "        #turn index into an integer\n",
    "        df_onehot = df_onehot.withColumn(\"event_index\", int_cast_udf(\"event_ind\"))\n",
    "\n",
    "        print(\"indexing time: \"+ str(time.time() - start_time))\n",
    "\n",
    "        #Generate a list of columns to drop\n",
    "        keep_cols = ['malicious','Trace','event','vec2string',\"event_index\"]\n",
    "        drop_cols = [col for col in df_onehot.columns  \n",
    "                     if col not in list_cols and col not in keep_cols]\n",
    "    \n",
    "        #i want to drop any columnn not in the column list or is the malicious column\n",
    "        df_onehot = df_onehot.drop(*drop_cols)\n",
    "        \n",
    "        #now do it for the indices\n",
    "        pivot_ind = df_onehot.groupBy('Trace').pivot('event').agg(first('malicious'),\n",
    "                                        first('event_index'))\n",
    "        df_onehot = pivot_ind.select('Trace',col('e1_first(malicious)').alias('malicious'),\n",
    "                                  array('e1_first(event_index)', 'e2_first(event_index)',\n",
    "                           'e3_first(event_index)','e4_first(event_index)', \n",
    "                           'e5_first(event_index)', 'e6_first(event_index)').alias('event_sequence'))\n",
    "        \n",
    "    print(\"total elapsed time: \"+ str(time.time() - start_time))\n",
    "    \n",
    "    return df_onehot,dict_mapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
