{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c33cce-a25f-4bc3-9742-e31e262f8612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d4d539-fe27-43fc-b80b-cb09a14eecf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to accept an event trace data frame and then encode it. Ideally we run this twice, once on the malicious\n",
    "#traces and again on benign traces. This implies that we run graphframes on both sets of events independently. \n",
    "\n",
    "#TODO: extract only the extensions, or declare file path an attribute \n",
    "\n",
    "def oneHotCol(df, colm, dict_mapping):\n",
    "    \n",
    "    #now action\n",
    "    #turn into numeric index before encoding\n",
    "    \n",
    "    num = colm+'_numeric'\n",
    "    sparse = colm+'_sparse'\n",
    "    indexer = StringIndexer(inputCol=colm, outputCol=num, handleInvalid=\"keep\")\n",
    "    indexer_fitted = indexer.fit(df)\n",
    "    df_indexed = indexer_fitted.transform(df)\n",
    "\n",
    "    encoder = OneHotEncoder(inputCols=[num], outputCols=[sparse],dropLast=False)\n",
    "    df_onehot = encoder.fit(df_indexed).transform(df_indexed)\n",
    "    df_onehot = df_onehot.drop(colm, num)\n",
    "\n",
    "    #set dict to mapping\n",
    "    dict_mapping[colm] = indexer_fitted.labels\n",
    "        \n",
    "    return df_onehot, dict_mapping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc9b0de-18bc-40df-b302-a371021a11b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trace_encode(df, list_cols):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #step one accept the event trace transpose it, and explode it. \n",
    "\n",
    "    #add \"trace index\" to keep track of traces. important for transposing back\n",
    "    df_transp = df.withColumn(\"Trace\", (monotonically_increasing_id() + 1))\n",
    "    df_transp = df_transp.select(\"Trace\", \n",
    "                                 *[col for col in df_transp.columns if col != \"Trace\"])\n",
    "\n",
    "    #drop all vertices\n",
    "    df_transp = df_transp.drop('a','b','c','d','e','f','g')\n",
    "\n",
    "    #transpose rows \n",
    "    stacked_df = df_transp.selectExpr(\n",
    "        \"Trace\", \n",
    "        \"posexplode(array(e1, e2, e3, e4, e5, e6)) as (pos, col)\"\n",
    "    ).select(\n",
    "        \"Trace\", \n",
    "        expr('''CASE pos \n",
    "        WHEN 0 THEN 'e1' \n",
    "        WHEN 1 THEN 'e2'\n",
    "        WHEN 2 THEN 'e3'\n",
    "        WHEN 3 THEN 'e4'\n",
    "        WHEN 4 THEN 'e5'\n",
    "        ELSE 'e6' END''').alias(\"event\"),\n",
    "        \"col\"\n",
    "    ).orderBy(\"Trace\",\"event\")\n",
    "\n",
    "    #explode columns\n",
    "    stacked_df = stacked_df.select(*stacked_df.columns, \"col.*\").drop('col')\n",
    "    \n",
    "    #instantiate dictionary and return df\n",
    "    dict_mapping = {}\n",
    "    df_onehot = stacked_df\n",
    "    \n",
    "    #for all columns to one hot, one hot, preserve mapping\n",
    "    for colm in list_cols:\n",
    "        df_onehot, dict_mapping = oneHotCol(df_onehot,colm, dict_mapping) \n",
    "    \n",
    "    print(\"elapsed time: \"+ str(time.time() - start_time))\n",
    "    \n",
    "    return df_onehot,dict_mapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
