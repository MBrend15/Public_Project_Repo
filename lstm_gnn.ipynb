{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd7a379-ea4d-4e49-ba96-40ae676d70fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/install/pip\n",
    "%pip install nvidia-cudnn-cu11==8.6.0.163 tensorflow==2.12.* --quiet\n",
    "# %pip install tensorflow_gnn --quiet\n",
    "# %pip install tensorflow_io --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d7fa78-5461-4d9a-897d-b14452f45396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 06:28:37.273607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 06:28:38.378915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import feature_column\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# import tensorflow_io as tfio\n",
    "# import tensorflow_gnn as tfgnn\n",
    "# from tensorflow_gnn import runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3766aaf5-5f59-4f4f-8fb0-0c28e77158ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 06:28:54.270806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 06:28:57.372460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 06:28:57.372750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# verify install \n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f876fa6b-6c75-4b3e-9bf2-4f664f948320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f953d05f-dcf9-4a60-8583-245b47ed15e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-aada5d66-3f71-46b1-a1f6-7866112ec362;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      "downloading https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar ...\n",
      "\t[SUCCESSFUL ] graphframes#graphframes;0.8.2-spark3.2-s_2.12!graphframes.jar (43ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.16!slf4j-api.jar (27ms)\n",
      ":: resolution report :: resolve 761ms :: artifacts dl 74ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-aada5d66-3f71-46b1-a1f6-7866112ec362\n",
      "\tconfs: [default]\n",
      "\t2 artifacts copied, 0 already retrieved (281kB/7ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 06:29:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 06:29:23 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2463851b-bfd8-40a2-8f3a-e9f9fd96faa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "pd.set_option('display.max_columns', None)\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb4fe4d-f90f-4bec-8e95-0132f34e0306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "embedding_dim = 64\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 10000\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "training_portion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c90ae-dfb5-480e-aab8-6be04dbd673e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5979c0f9-a145-4c38-85cd-7b78fa8933d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3a://sapient-bucket-trusted/prod/tensor_sample_data/test_holdout/*\").cache().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd588c1-74a1-4864-b542-6c703d8e597e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "466d55ae-638f-4e81-b9bd-46507460121c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trace             2598111\n",
       "malicious         2598111\n",
       "event_sequence    2598111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbdca15f-a656-4c49-9f2b-e8fe9eadd3df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598111"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0546378f-ef00-44ba-a7b2-dbfc142e87d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trace              int64\n",
       "malicious          int32\n",
       "event_sequence    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebde825-28b7-428d-9cdc-74cf9205f49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71bb8452-893b-44f2-ab04-197dad0f6faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_sequences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d1a09df-4ef8-411a-867c-e6fbaec8e361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data conversion - https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35\n",
    "training_data = df['event_sequence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a21fb869-7231-4801-ac4a-17f6e822aff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_label = df['malicious'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effec8f6-9115-4616-a923-60b2125b2f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = int(len(training_label) * training_portion)\n",
    "\n",
    "train_set = training_data[0: train_size]\n",
    "train_labels = training_label[0: train_size]\n",
    "validation_set = training_data[train_size:]\n",
    "validation_labels = training_label[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ce84b03-0816-45bc-9548-2c3cc01ad766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2d27e3-2c36-43ed-95f6-46f49be5770f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8122f80-6f2b-4cd8-bc07-3a05679892b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_set)\n",
    "train_padded = tf.keras.utils.pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2e27a69-e616-4749-91f5-eaa734d351cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences(validation_set)\n",
    "validation_padded = tf.keras.utils.pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec727a6-4cf6-4796-a285-2be7f3061279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices([i for i in dataframe])\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e812173d-af92-4b28-ac82-48f731d67f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = df_to_dataset(train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc41c754-8d26-47bf-bce2-17df3922e0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_ds = df_to_dataset(validation_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04dfd69c-e84f-4de3-a707-a28000c1024b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2677810, 2677811, 2677812, 2677813, 2677814, 398041]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de322755-34e4-4642-bc31-d4e0d3dedb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee5f14c9-383e-4f88-9cd0-ace2e657b0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = tf.reshape(train_padded, (len(train_padded),6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ecb79f49-7b94-43b8-8e06-73763a49df23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_ds = tf.reshape(validation_padded, (len(validation_padded),6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfee1da-8c36-49c0-bcf0-cc3ce098c3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a2823-e0d1-4c13-8698-f55e74ab4e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56bf51c7-d175-4539-a4c9-d3d5b8d4fa0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(set([x for l in train_sequences + validation_sequences for x in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a07ff125-393d-4b5f-996d-f8500f3daba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12463016"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "280cb113-a86a-4592-b2b9-d72b96b75c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_ds = tf.ragged.constant(train_labels)\n",
    "validation_labels_ds = tf.ragged.constant(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a278658-565d-4a5a-9836-7fe2f4c9bcf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b13c7-7369-46a1-865d-37f58f71c96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "765eb624-b299-48ce-b93a-737cd2ba2614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2078488"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b354ed4b-e702-4280-9604-0ceff14f1faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2598111, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5646e260-fd1f-4d4f-8364-43ac57f24e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "X = keras.Input(shape=[len(train_ds), 6], dtype=tf.int64, ragged=True)\n",
    "l1 = keras.layers.Embedding(df.shape[0], 16)(X)\n",
    "l2 = tf.reduce_sum(l1, axis=2) #To calculate the dense feature vector for each timestep.\n",
    "l3 = keras.layers.LSTM(32, use_bias=False)(l2)\n",
    "l4 = keras.layers.Dense(32, activation='sigmoid')(l3)\n",
    "l5 = keras.layers.Activation(tf.nn.relu)(l4)\n",
    "output = tf.keras.layers.Dense(1)(l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fae94dc2-2035-4ec6-9947-a80ea43a828d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(X, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7704297-2425-4cc6-b559-09d52247ea43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 2078488, 6)]      0         \n",
      "                                                                 \n",
      " embedding_10 (Embedding)    (None, 2078488, 6, 16)    41569776  \n",
      "                                                                 \n",
      " tf.math.reduce_sum_7 (TFOpL  (None, 2078488, 16)      0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 32)                6144      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,577,009\n",
      "Trainable params: 41,577,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "832ba3e4-61b9-4ffb-ad93-7e65c815be8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f2e22e6-8cb8-4119-a9b0-b6b54a03cfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_4\" is incompatible with the layer: expected shape=(None, 2078488, 6), found shape=(None, 6, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_labels_ds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefxzgfg08.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_4\" is incompatible with the layer: expected shape=(None, 2078488, 6), found shape=(None, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "                x=train_ds,\n",
    "                y=train_labels_ds,\n",
    "                batch_size=32,\n",
    "                epochs=num_epochs,\n",
    "                verbose=1,\n",
    "                callbacks=None,\n",
    "                validation_split=0.0,\n",
    "                validation_data=(validation_ds, validation_labels_ds),\n",
    "                shuffle=True,\n",
    "                class_weight=None,\n",
    "                sample_weight=None,\n",
    "                initial_epoch=0,\n",
    "                steps_per_epoch=None,\n",
    "                validation_steps=None,\n",
    "                validation_batch_size=None,\n",
    "                validation_freq=1,\n",
    "                max_queue_size=10,\n",
    "                workers=1,\n",
    "                use_multiprocessing=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7803b-44d0-4e95-9727-00afcf3d72f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c8d1156-430f-4880-b2f8-9c3d1c016b62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23adc5-ff86-4815-b075-b8aeca0bc9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8835457a-1be9-4544-9754-43f9d2d7d4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
    "    tf.keras.layers.Embedding(df.shape[0], embedding_dim, input_length=6),\n",
    "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14fb5846-ea0a-422e-9cb7-f4e93b042ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 6, 64)             166279104 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6, 64)             4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6, 6)              390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,283,654\n",
      "Trainable params: 166,283,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67a629d3-2484-4024-afad-52db6a0caf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b441ed2-6561-488b-b196-92568a84dce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 05:19:12.485880: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: required broadcastable shapes\n",
      "2023-03-27 05:19:12.485942: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: required broadcastable shapes\n",
      "\t [[{{node Equal}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_32527/3921490621.py\", line 2, in <module>\n      history = model.fit(train_padded, train_ds, epochs=num_epochs,\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/metrics/accuracy_metrics.py\", line 459, in sparse_categorical_accuracy\n      matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 971, in sparse_categorical_matches\n      matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_1990]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_32527/3921490621.py\", line 2, in <module>\n      history = model.fit(train_padded, train_ds, epochs=num_epochs,\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/metrics/accuracy_metrics.py\", line 459, in sparse_categorical_accuracy\n      matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 971, in sparse_categorical_matches\n      matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_1990]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(train_padded, train_ds, epochs=num_epochs, \n",
    "                    validation_data=(validation_padded, validation_ds), \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25487fa8-f41c-42c8-8d6e-e4ce28c9afd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ca34a-ba1a-457d-9645-a3efc25c6914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9542f-b32e-4be8-8051-f93fd8a7ad16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf71b1c-60cd-4e08-986c-356975e9846c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c87225-223b-4560-834b-e8d5fa3f1769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds = tf.data.Dataset.from_tensor_slices(([i for i in df['event_sequence']], df['Trace'], df['malicious']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906da94f-83b9-4e39-bf12-e2f85020c471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input data based on - https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda2c41-636d-4818-86b9-6f02a4eff507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92187562-6f81-4256-8f5e-d9cb67eb999e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77558b0-2982-4909-8721-9063183a35b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('malicious')\n",
    "  ds = tf.data.Dataset.from_tensor_slices(([i for i in df['event_sequence']], df['malicious']))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2cd60-bf09-40ec-995f-3704dee0f926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A utility method to create a feature column\n",
    "# and to transform a batch of data\n",
    "def make_features(feature_column):  \n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7865ee9-305a-4030-b338-a7ad6d61eb1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b65b7a-a549-44a5-b68f-7ad316ff7ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e5b50-1228-4da2-9d52-363ea1c3b2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(set([x[0] for x in df['event_sequence']] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bd256-a538-4e91-af6c-55ebc9d553f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4b960-15fb-4d72-9a0f-5c877aeb608c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = vocab_size\n",
    "sequence_length = 6\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length.\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6516a77-080b-409c-88f8-0706b71c2e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dceee2-19ea-4bd8-a237-f4642150c1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc404c7-0e0c-431a-bdd9-46feff911b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ee91f-e564-435f-981b-cb9d2db6791d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(tf.reshape(text_ds, (len(text_ds),6,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9c9b2-560e-46cf-9f4a-d7bc3a3df9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sequence_batch, label_batch in train_ds.take(1):\n",
    "  print('A batch of sequences:', sequence_batch ) # list(feature_batch.keys()))\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed4bec-e032-4c50-8040-403dca30bd64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  #feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb9974-c737-4ee1-bfcb-9ca73fdb8bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0fb3b-6c0b-477a-9713-33d2e3fbd03f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11680336-560e-43a3-bed2-5cd8b32b2467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb8a46-8dda-4e8b-92e9-1c6c37307425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed6996-0479-4d90-bd22-c8c5b0b554b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = tf.ragged.constant([ [[940, 203, 668, 387, 790, 320, 939, 185],[315, 515, 791, 181, 939, 787]], \n",
    "                             [[564, 205], [820, 180, 993, 739]] ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd278b-2461-45c7-a0b8-663b684d8266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/70399367/sparse-feature-vector-sequence-as-input-to-lstm\n",
    "X = keras.Input(shape=[inputs.shape[0], inputs.shape[1]], dtype=tf.int64, ragged=True)\n",
    "l1 = keras.layers.Embedding(inputs.shape[0], 16)(X)\n",
    "l2 = tf.reduce_sum(l1, axis=2) #To calculate the dense feature vector for each timestep.\n",
    "l3 = keras.layers.LSTM(32, use_bias=False)(l2)\n",
    "l4 = keras.layers.Dense(32, activation='sigmoid')(l3)\n",
    "l5 = keras.layers.Activation(tf.nn.relu)(l4)\n",
    "output = tf.keras.layers.Dense(1)(l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc17e7b-c282-4d74-b5d6-9e5a0a34e1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pad the sequences so they are all the same length\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9da64-515a-4e03-9c18-5fd4b7597b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15040e-c439-4671-9f4f-9650d0aacdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121cb81d-4974-47dc-ab8c-3a1e62cb06ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df86ab3-e181-4df7-bba9-e79255ed6cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0dac90-5f83-4b38-80b8-23f12dfd7ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051486e-6945-4ba7-89ae-06096c07f8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Building input data\n",
    "test01 = ([[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]],'label1')\n",
    "test02 = ([[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1],[0,0,0,0]],'label2')\n",
    "test03 = ([[1,1,1,1],[1,1,1,1],[1,1,1,1],[0,0,0,0],[1,1,1,1]],'label3')\n",
    "test04 = ([[1,1,1,1],[0,0,0,0],[1,1,1,1],[1,1,1,1],[1,1,1,1]],'label1')\n",
    "test_data = [test01,test02,test03,test04]\n",
    "\n",
    "\n",
    "##DataFrame from data\n",
    "columns = ['feature','label']\n",
    "t_df = pd.DataFrame(data = test_data, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1727f51-7c60-4a36-b708-ca7abba537c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d2353-054b-44c3-a678-a364bb570301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b194dd-310f-4588-8d3c-8034fad0a5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11696d6d-be3b-4b29-b47c-c466f9428a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61b500-dfb9-4121-ab38-57876f9e7087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858e2a9-275c-4a65-9bca-a8d41c7d0196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(([i for i in t_df['feature']], t_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8947cd1-a1b0-4324-87f0-c3eccb240604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33794c4-ada9-4c48-ba2f-c59faea18c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/70399367/sparse-feature-vector-sequence-as-input-to-lstm\n",
    "X = keras.Input(shape=[t_df.shape[0], t_df.shape[1]], dtype=tf.int64, ragged=True)\n",
    "l1 = keras.layers.Embedding(t_df.shape[0], 16)(dataset)\n",
    "l2 = tf.reduce_sum(l1, axis=2) #To calculate the dense feature vector for each timestep.\n",
    "l3 = keras.layers.LSTM(32, use_bias=False)(l2)\n",
    "l4 = keras.layers.Dense(32, activation='sigmoid')(l3)\n",
    "l5 = keras.layers.Activation(tf.nn.relu)(l4)\n",
    "output = tf.keras.layers.Dense(1)(l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24171b8-c0c0-445d-aca9-132c0dd7bbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608f9fb-dfb1-478b-917f-3c1eadd25033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9a2ea-7587-479f-a058-fb86c06767a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc39d51-9ae4-4e9a-bc2d-c191fb968110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499ce4c-9627-4a04-a5d0-567c7d2f0c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a371f8e-63ac-4a4d-a2d6-85d3b3f65c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736f048-6568-44ec-bde1-e8696bedcc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
