{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b20b575-dcda-4a51-87fd-c3104166c2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a717a56a-225c-45ac-8ba9-efdea102abe1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 218ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a717a56a-225c-45ac-8ba9-efdea102abe1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/7ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/17 03:44:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/17 03:44:51 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f752d7-2f69-493b-a03a-0acb4db74db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295239d-3d08-4f7d-bef1-1de64e1d0b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51475f9f-73c6-477b-a45e-d3f76a3d4d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 6\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "input_len = 10000\n",
    "\n",
    "# place to save model after\n",
    "ckt_path_generator = 'saved_model/generator'\n",
    "ckt_path_tokenizer = 'saved_model/tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc80e719-db06-4b06-bd48-056d924b2576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "with open(ckt_path_tokenizer, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b51b5a-6545-488a-8edb-f9270efa797d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "vocab_count = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76b6f5d-1ae6-4632-8570-8b0751b5f695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_count, activation='softmax')),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "            tf.keras.layers.LSTM(128, return_sequences=False),\n",
    "            tf.keras.layers.Dense(2, activation='tanh'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, sequence_length, vocab_count], minval=1, maxval=vocab_count, dtype=tf.int32)\n",
    "    return n\n",
    "\n",
    "def generate_fake_samples(generator):\n",
    "    # generate points in latent space & pass through generator\n",
    "    x = generator.predict(generate_latent_space(), verbose=0)\n",
    "    # create class labels\n",
    "    y = zeros((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "# def generate_real_samples():\n",
    "#     x = seq_enc_tensor\n",
    "#     # create class labels\n",
    "#     y = ones((input_len,1))\n",
    "#     return x, y\n",
    "\n",
    "def generate_real_samples():\n",
    "    # each time, this should produce a different sample of the larger data\n",
    "    # get only malicious data\n",
    "    ds_mal = ds.filter( col('mal_trace') == 1).cache()\n",
    "\n",
    "    # now randomly sample from the malicious data\n",
    "    n = input_len  # number of rows to select\n",
    "    total_rows = ds_mal.count()\n",
    "    fraction = float(n) / float(total_rows)\n",
    "    df_sample, _ = ds_mal.randomSplit([fraction, 1.0 - fraction], seed=42)\n",
    "    df_sample = df_sample.limit(n)\n",
    "\n",
    "    ds.unpersist()\n",
    "    dm_events = df_sample.select('event_sequence').rdd.flatMap(lambda x: x).collect()\n",
    "    dm_labels = df_sample.select('mal_trace').rdd.flatMap(lambda x: x).collect()\n",
    "    # one hot encode the data\n",
    "    dm_sequences = tokenizer.texts_to_sequences(dm_events)\n",
    "    dm_padded = tf.keras.utils.pad_sequences(dm_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    seq_enc_tensor = tf.one_hot(dm_padded, vocab_count)\n",
    "    x = seq_enc_tensor\n",
    "    # create class labels\n",
    "    y = ones((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def make_samples(g_model):\n",
    "    x_gen, y_gen = generate_fake_samples(g_model)\n",
    "    new_seq_enc = tf.argmax(x_gen, axis=-1)\n",
    "    new_seq_texts = tokenizer.sequences_to_texts(new_seq_enc.numpy())\n",
    "    gen_events = [[','.join(n.split())] for n in new_seq_texts]\n",
    "    gen_labels = [1]*input_len\n",
    "    trace_list = [99999]*input_len\n",
    "    d_gen = list(zip(trace_list, gen_labels, gen_labels, gen_events))\n",
    "    df_gen = spark.createDataFrame(d_gen, ['Trace', 'mal_trace', 'malicious', 'event_sequence'])\n",
    "    return df_gen\n",
    "\n",
    "def train(g_model, d_model, gan_model, epochs=5, n_eval=50):\n",
    "    d_acc_history = []\n",
    "    d_loss_history = []\n",
    "    g_acc_history = []\n",
    "    g_loss_history = []\n",
    "    sample_count_history = []\n",
    "\n",
    "    d_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    g_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_real_samples()\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model)\n",
    "\n",
    "        # update discriminator\n",
    "        d_real_loss = d_model.train_on_batch(x_real, y_real)\n",
    "        d_fake_loss = d_model.train_on_batch(x_fake, y_fake)\n",
    "        d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "\n",
    "        d_real_pred = d_model.predict_on_batch(x_real)\n",
    "        d_fake_pred = d_model.predict_on_batch(x_fake)\n",
    "\n",
    "        d_metric.update_state(tf.concat([y_real, y_fake], axis=0), tf.concat([d_real_pred, d_fake_pred], axis=0))\n",
    "        d_acc = d_metric.result().numpy()\n",
    "\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        y_gan = ones((input_len, 1))\n",
    "        g_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_pred = gan_model.predict_on_batch(x_gan)\n",
    "        g_metric.update_state(tf.one_hot(tf.cast(y_gan, tf.int32), depth=2), gan_pred)\n",
    "        g_acc = g_metric.result().numpy()\n",
    "\n",
    "        d_acc_history.append(d_acc)\n",
    "        d_loss_history.append(d_loss)\n",
    "        g_acc_history.append(g_acc)\n",
    "        g_loss_history.append(g_loss)\n",
    "\n",
    "        if i % n_eval == 0:\n",
    "            gen = make_samples(g_model)\n",
    "            dc_seq = gen.groupBy(\"mal_trace\").agg(countDistinct('event_sequence')).select('count(event_sequence)').collect()[0]['count(event_sequence)']\n",
    "            seq_len = len(gen.limit(1).select('event_sequence').collect()[0]['event_sequence'][0])\n",
    "            sample_count_history.append(dc_seq)\n",
    "            if i % 100 == 0:\n",
    "                # print(f\"The total number of distinct generated samples is: {dc_seq} and had a sequence that has a length {seq_len}\")\n",
    "                print(f\"Epoch {i}: Discriminator Loss: {d_loss}, Discriminator Accuracy: {d_acc}, Generator Loss: {g_loss}, Generator Accuracy: {g_acc}\")\n",
    "    # checkpoint model after completion of epochs\n",
    "    g_model.save(ckt_path_generator)\n",
    "\n",
    "    return d_acc_history, d_loss_history, g_acc_history, g_loss_history, sample_count_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2bc25-832b-4b86-bf51-609dde91aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbed33-f7b4-4700-9249-e9928b16ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffeff66a-b0b6-47d9-b54a-601d60790fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fbe5ef67880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "generator = define_generator()\n",
    "generator.load_weights(ckt_path_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccaa0fd-e3db-4baa-810a-8d58f48e42b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_samples(generator):\n",
    "    x_gen, y_gen = generate_fake_samples(generator)\n",
    "    new_seq_enc = tf.argmax(x_gen, axis=-1)\n",
    "    new_seq_texts = tokenizer.sequences_to_texts(new_seq_enc.numpy())\n",
    "    gen_events = [[','.join(n.split())] for n in new_seq_texts]\n",
    "    gen_labels = [1]*input_len\n",
    "    trace_list = [99999]*input_len\n",
    "    d_gen = list(zip(trace_list, gen_labels, gen_labels, gen_events))\n",
    "    df_gen = spark.createDataFrame(d_gen, ['Trace', 'mal_trace', 'malicious', 'event_sequence'])\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de07577f-c420-4f3a-9b78-f8656efe1f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number of iterations\n",
    "num_iterations = 50\n",
    "\n",
    "#initialize combined dataframe\n",
    "gen_samp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922d1ace-1ae6-41e2-a726-743bd1382ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over the input parameters\n",
    "for param in range(num_iterations):\n",
    "    # Create a dataframe with the current input parameter\n",
    "    df = make_samples(generator)\n",
    "    # filter out rows where there is no data\n",
    "    # Append the dataframe to the combined dataframe using union\n",
    "    if gen_samp is None:\n",
    "        gen_samp = df\n",
    "    else:\n",
    "        gen_samp = gen_samp.union(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cf3461-d18a-4683-bde9-2c5211b18651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop the first row\n",
    "w = Window.orderBy(\"event_sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cad3d4d9-7bb9-49b2-a543-234de856cf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dist = gen_samp.select(*gen_samp.columns).distinct().sort( col('event_sequence').asc())\n",
    "gen_dist = gen_dist.withColumn(\"row_num\", row_number().over(w)).filter(\"row_num != 1\").drop(\"row_num\").cache()\n",
    "gen_dist.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1947bacc-608d-450e-b4c6-7f6475d90049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+--------------+\n",
      "|Trace|mal_trace|malicious|event_sequence|\n",
      "+-----+---------+---------+--------------+\n",
      "+-----+---------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_dist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99aee1f3-7a5a-4ede-a40c-dd5d6c2daac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>mal_trace</th>\n",
       "      <th>malicious</th>\n",
       "      <th>event_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Trace, mal_trace, malicious, event_sequence]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dist.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42f6e83f-bc9e-4eaf-a91c-edf6370c2210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19513/1688131981.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdc_gen_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mal_trace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountDistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'event_sequence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count(event_sequence)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count(event_sequence)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The total number of distinct generated samples is: {dc_gen_seq}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dc_gen_seq = gen_dist.groupBy(\"mal_trace\").agg(countDistinct('event_sequence')).select('count(event_sequence)').collect()[0]['count(event_sequence)']\n",
    "print(f\"The total number of distinct generated samples is: {dc_gen_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024ceee-37df-4df8-8fe9-cea5f9f3522d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "num_partitions = 20\n",
    "dup_data = gen_dist.repartition(num_partitions)\n",
    "for i in range(n // num_partitions):\n",
    "    dup_data = dup_data.union(gen_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57202612-6797-4012-9dcc-c16c724a161a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dup_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c6040-b53c-43c4-ad6c-95a884156dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dup_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f702f0e-bf8f-49d6-9850-17f7cfcb86fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gens.write.option(\"maxRecordsPerFile\", 300000).mode(\"overwrite\").parquet(\"s3a://sapient-bucket-trusted/prod/graph/motifs/gen_malicious/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc526ca-7176-4386-95d6-208067c2a39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
