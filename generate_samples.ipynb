{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f752d7-2f69-493b-a03a-0acb4db74db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295239d-3d08-4f7d-bef1-1de64e1d0b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51475f9f-73c6-477b-a45e-d3f76a3d4d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 6\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "input_len = 10000\n",
    "\n",
    "# place to save model after\n",
    "ckt_path_generator = 'saved_model/generator'\n",
    "ckt_path_tokenizer = 'saved_model/tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80e719-db06-4b06-bd48-056d924b2576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "with open(ckt_path_tokenizer, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f76b6f5d-1ae6-4632-8570-8b0751b5f695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_count, activation='softmax')),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(sequence_length, vocab_count)),\n",
    "            tf.keras.layers.LSTM(128, return_sequences=False),\n",
    "            tf.keras.layers.Dense(2, activation='tanh'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, sequence_length, vocab_count], minval=1, maxval=vocab_count, dtype=tf.int32)\n",
    "    return n\n",
    "\n",
    "def generate_fake_samples(generator):\n",
    "    # generate points in latent space & pass through generator\n",
    "    x = generator.predict(generate_latent_space(), verbose=0)\n",
    "    # create class labels\n",
    "    y = zeros((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "# def generate_real_samples():\n",
    "#     x = seq_enc_tensor\n",
    "#     # create class labels\n",
    "#     y = ones((input_len,1))\n",
    "#     return x, y\n",
    "\n",
    "def generate_real_samples():\n",
    "    # each time, this should produce a different sample of the larger data\n",
    "    # get only malicious data\n",
    "    ds_mal = ds.filter( col('mal_trace') == 1).cache()\n",
    "\n",
    "    # now randomly sample from the malicious data\n",
    "    n = input_len  # number of rows to select\n",
    "    total_rows = ds_mal.count()\n",
    "    fraction = float(n) / float(total_rows)\n",
    "    df_sample, _ = ds_mal.randomSplit([fraction, 1.0 - fraction], seed=42)\n",
    "    df_sample = df_sample.limit(n)\n",
    "\n",
    "    ds.unpersist()\n",
    "    dm_events = df_sample.select('event_sequence').rdd.flatMap(lambda x: x).collect()\n",
    "    dm_labels = df_sample.select('mal_trace').rdd.flatMap(lambda x: x).collect()\n",
    "    # one hot encode the data\n",
    "    dm_sequences = tokenizer.texts_to_sequences(dm_events)\n",
    "    dm_padded = tf.keras.utils.pad_sequences(dm_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    seq_enc_tensor = tf.one_hot(dm_padded, vocab_count)\n",
    "    x = seq_enc_tensor\n",
    "    # create class labels\n",
    "    y = ones((input_len,1))\n",
    "    return x, y\n",
    "\n",
    "def make_samples(g_model):\n",
    "    x_gen, y_gen = generate_fake_samples(g_model)\n",
    "    new_seq_enc = tf.argmax(x_gen, axis=-1)\n",
    "    new_seq_texts = tokenizer.sequences_to_texts(new_seq_enc.numpy())\n",
    "    gen_events = [[','.join(n.split())] for n in new_seq_texts]\n",
    "    gen_labels = [1]*input_len\n",
    "    trace_list = [99999]*input_len\n",
    "    d_gen = list(zip(trace_list, gen_labels, gen_labels, gen_events))\n",
    "    df_gen = spark.createDataFrame(d_gen, ['Trace', 'mal_trace', 'malicious', 'event_sequence'])\n",
    "    return df_gen\n",
    "\n",
    "def train(g_model, d_model, gan_model, epochs=5, n_eval=50):\n",
    "    d_acc_history = []\n",
    "    d_loss_history = []\n",
    "    g_acc_history = []\n",
    "    g_loss_history = []\n",
    "    sample_count_history = []\n",
    "\n",
    "    d_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    g_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_real_samples()\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model)\n",
    "\n",
    "        # update discriminator\n",
    "        d_real_loss = d_model.train_on_batch(x_real, y_real)\n",
    "        d_fake_loss = d_model.train_on_batch(x_fake, y_fake)\n",
    "        d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "\n",
    "        d_real_pred = d_model.predict_on_batch(x_real)\n",
    "        d_fake_pred = d_model.predict_on_batch(x_fake)\n",
    "\n",
    "        d_metric.update_state(tf.concat([y_real, y_fake], axis=0), tf.concat([d_real_pred, d_fake_pred], axis=0))\n",
    "        d_acc = d_metric.result().numpy()\n",
    "\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        y_gan = ones((input_len, 1))\n",
    "        g_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_pred = gan_model.predict_on_batch(x_gan)\n",
    "        g_metric.update_state(tf.one_hot(tf.cast(y_gan, tf.int32), depth=2), gan_pred)\n",
    "        g_acc = g_metric.result().numpy()\n",
    "\n",
    "        d_acc_history.append(d_acc)\n",
    "        d_loss_history.append(d_loss)\n",
    "        g_acc_history.append(g_acc)\n",
    "        g_loss_history.append(g_loss)\n",
    "\n",
    "        if i % n_eval == 0:\n",
    "            gen = make_samples(g_model)\n",
    "            dc_seq = gen.groupBy(\"mal_trace\").agg(countDistinct('event_sequence')).select('count(event_sequence)').collect()[0]['count(event_sequence)']\n",
    "            seq_len = len(gen.limit(1).select('event_sequence').collect()[0]['event_sequence'][0])\n",
    "            sample_count_history.append(dc_seq)\n",
    "            if i % 100 == 0:\n",
    "                # print(f\"The total number of distinct generated samples is: {dc_seq} and had a sequence that has a length {seq_len}\")\n",
    "                print(f\"Epoch {i}: Discriminator Loss: {d_loss}, Discriminator Accuracy: {d_acc}, Generator Loss: {g_loss}, Generator Accuracy: {g_acc}\")\n",
    "    # checkpoint model after completion of epochs\n",
    "    g_model.save(ckt_path_generator)\n",
    "\n",
    "    return d_acc_history, d_loss_history, g_acc_history, g_loss_history, sample_count_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2bc25-832b-4b86-bf51-609dde91aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbed33-f7b4-4700-9249-e9928b16ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffeff66a-b0b6-47d9-b54a-601d60790fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f058c17f670>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "generator = define_generator()\n",
    "generator.load_weights(ckt_path_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ccaa0fd-e3db-4baa-810a-8d58f48e42b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_samples(generator):\n",
    "    x_gen, y_gen = generate_fake_samples(generator)\n",
    "    new_seq_enc = tf.argmax(x_gen, axis=-1)\n",
    "    new_seq_texts = tokenizer.sequences_to_texts(new_seq_enc.numpy())\n",
    "    gen_events = [[','.join(n.split())] for n in new_seq_texts]\n",
    "    gen_labels = [1]*input_len\n",
    "    trace_list = [99999]*input_len\n",
    "    d_gen = list(zip(trace_list, gen_labels, gen_labels, gen_events))\n",
    "    df_gen = spark.createDataFrame(d_gen, ['Trace', 'mal_trace', 'malicious', 'event_sequence'])\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de07577f-c420-4f3a-9b78-f8656efe1f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number of iterations\n",
    "num_iterations = 50\n",
    "\n",
    "#initialize combined dataframe\n",
    "gen_samp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "922d1ace-1ae6-41e2-a726-743bd1382ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over the input parameters\n",
    "for param in range(num_iterations):\n",
    "    # Create a dataframe with the current input parameter\n",
    "    df = make_samples(generator)\n",
    "    # filter out rows where there is no data\n",
    "    # Append the dataframe to the combined dataframe using union\n",
    "    if gen_samp is None:\n",
    "        gen_samp = df\n",
    "    else:\n",
    "        gen_samp = gen_samp.union(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49cf3461-d18a-4683-bde9-2c5211b18651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop the first row\n",
    "w = Window.orderBy(\"event_sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cad3d4d9-7bb9-49b2-a543-234de856cf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dist = gen_samp.select(*gen_samp.columns).distinct().sort( col('event_sequence').asc())\n",
    "gen_dist = gen_dist.withColumn(\"row_num\", row_number().over(w)).filter(\"row_num != 1\").drop(\"row_num\").cache()\n",
    "gen_dist.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1947bacc-608d-450e-b4c6-7f6475d90049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+--------------------+\n",
      "|Trace|mal_trace|malicious|      event_sequence|\n",
      "+-----+---------+---------+--------------------+\n",
      "|99999|        1|        1|[1000000000010000...|\n",
      "+-----+---------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_dist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99aee1f3-7a5a-4ede-a40c-dd5d6c2daac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>mal_trace</th>\n",
       "      <th>malicious</th>\n",
       "      <th>event_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[10000000000100001000100001000000000001000]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trace  mal_trace  malicious                               event_sequence\n",
       "0  99999          1          1  [10000000000100001000100001000000000001000]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dist.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42f6e83f-bc9e-4eaf-a91c-edf6370c2210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of distinct generated samples is: 1\n"
     ]
    }
   ],
   "source": [
    "dc_gen_seq = gen_dist.groupBy(\"mal_trace\").agg(countDistinct('event_sequence')).select('count(event_sequence)').collect()[0]['count(event_sequence)']\n",
    "print(f\"The total number of distinct generated samples is: {dc_gen_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e024ceee-37df-4df8-8fe9-cea5f9f3522d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "num_partitions = 20\n",
    "dup_data = gen_dist.repartition(num_partitions)\n",
    "for i in range(n // num_partitions):\n",
    "    dup_data = dup_data.union(gen_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57202612-6797-4012-9dcc-c16c724a161a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d26c6040-b53c-43c4-ad6c-95a884156dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>mal_trace</th>\n",
       "      <th>malicious</th>\n",
       "      <th>event_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[10000000000100001000100001000000000001000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[10000000000100001000100001000000000001000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[10000000000100001000100001000000000001000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[10000000000100001000100001000000000001000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[10000000000100001000100001000000000001000]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trace  mal_trace  malicious                               event_sequence\n",
       "0  99999          1          1  [10000000000100001000100001000000000001000]\n",
       "1  99999          1          1  [10000000000100001000100001000000000001000]\n",
       "2  99999          1          1  [10000000000100001000100001000000000001000]\n",
       "3  99999          1          1  [10000000000100001000100001000000000001000]\n",
       "4  99999          1          1  [10000000000100001000100001000000000001000]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f702f0e-bf8f-49d6-9850-17f7cfcb86fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gens.write.option(\"maxRecordsPerFile\", 300000).mode(\"overwrite\").parquet(\"s3a://sapient-bucket-trusted/prod/graph/motifs/gen_malicious/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc526ca-7176-4386-95d6-208067c2a39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
