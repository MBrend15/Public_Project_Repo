{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: Don't push the dataset to Github. The file paths below match my computer but may need to be adjusted for wherever you saved the data.\n",
    "\n",
    "Definitions of terms:\n",
    "\n",
    "- full_ratings - df of all 25M ratings from MovieLens\n",
    "- ratings_sample - df of 5% of the full ratings csv\n",
    "- ratings - df merged ratings_sample w/ movies to include movie title\n",
    "- movies - df with one row for every film\n",
    "- tags - df with one row for every tag\n",
    "- wiki_list - df with cult movies, release year,  director\n",
    "- oscars - df with oscar best picture nominees\n",
    "- links - df with movieid, imdbid, tmdbid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 25M ratings dataset as 'full_ratings'\n",
    "full_ratings = pd.read_csv('../ml-25m/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of number of ratings per movie (full dataset)\n",
    "full_ratings.groupby('movieId')['rating'].count().sort_values().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random sample (5% of all rows) to 'ratings' dataframe\n",
    "# ratings = full_ratings.sample(frac = 0.01) \n",
    "all_movies = pd.read_csv('../ml-25m/movies.csv')\n",
    "tags = pd.read_csv('../ml-25m/tags.csv')\n",
    "wiki_list = pd.read_csv('../Wikipedia_cult.csv')\n",
    "oscars = pd.read_csv('../oscars.csv')\n",
    "links = pd.read_csv('../ml-25m/links.csv', converters={'imdbId': lambda x: str(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter all_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add columns to Movies DataFrame\n",
    "- Average rating per movie (avg_rating)\n",
    "- Total number of ratings per movie (ratings_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_movies.set_index('movieId',inplace = True)\n",
    "#groupedmovies = full_ratings.groupby('movieId')\n",
    "#all_movies['avg_rating'] = groupedmovies.mean()['rating']\n",
    "#all_movies['ratings_count'] = groupedmovies.count()['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of movie averages\n",
    "avgmovies = pd.DataFrame(full_ratings.groupby('movieId')['rating'].mean())\n",
    "# DataFrame of ratings count per movies\n",
    "countmovies = pd.DataFrame(full_ratings.groupby('movieId')['rating'].count())\n",
    "# Merge into one DataFrame\n",
    "new_movie_cols = avgmovies.merge(countmovies, left_index=True, right_index=True)\n",
    "new_movie_cols.columns = ['avg_rating','ratings_count']\n",
    "# Merge onto original movies dataframe\n",
    "all_movies = all_movies.merge(new_movie_cols, left_on='movieId', right_index=True)\n",
    "#Filter out all movies with fewer than 36 ratings\n",
    "movies = all_movies[all_movies['ratings_count'] > 35]\n",
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new columns to movie dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add column for release year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_year(row):\n",
    "    \"\"\"Takes a row that has the release year in the title and returns the release year\"\"\"\n",
    "    title = row['title']\n",
    "    title = title.strip()\n",
    "    if '(' in title:\n",
    "        if title[-6] + title[-1] == '()' and title[-5] in '12':\n",
    "            # makes year an integer\n",
    "            year = int(title[-5:-1])\n",
    "            newtitle = title[:-7]\n",
    "            return year,newtitle\n",
    "        else:\n",
    "            return np.NaN,title\n",
    "    else:\n",
    "        return np.NaN,title\n",
    "\n",
    "# Create 2 new columns in movies dataframe: the release year and a shortened title \n",
    "movies['release_year'] = movies.apply(lambda x: release_year(x)[0], axis=1)\n",
    "movies['short_title'] = movies.apply(lambda x: release_year(x)[1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split genre column into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_clean(row):\n",
    "    \"\"\"Takes a row with a column 'genres' w/ pipe seperators and returns a list of each item.\"\"\"\n",
    "    x = row['genres'].split('|')\n",
    "    return x\n",
    "\n",
    "# Add 'genre_clean' column that contains an alphabetical list of the movie's genres.\n",
    "# I have no idea why this has to run twice (once with the [0] and then without) but it's the only way I can make it work.\n",
    "movies['genre_clean'] = movies.apply(lambda x: genre_clean(x)[0], axis=1)\n",
    "movies['genre_clean'] = movies.apply(lambda x: genre_clean(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clean Wikipedia list titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_the(row):\n",
    "    \"\"\"Takes a row with column 'Title' and returns title in the same MovieLens format (Title, The)\"\"\"\n",
    "    if row['Title'][0:4] == 'The ':\n",
    "        beginning = row['Title'][4:]\n",
    "        end = ', The'\n",
    "        return beginning + end\n",
    "    else:\n",
    "        return row['Title']\n",
    "\n",
    "# Add 'short_title' column to wiki dataframe (to match movies df col title)\n",
    "wiki_list['short_title'] = wiki_list.apply(lambda x: move_the(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clean release year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_year(row):\n",
    "    \"\"\"Takes a row with column 'Year' and returns the year as a float.\n",
    "       If the year is a range of years, such as for a series, it returns\n",
    "       the start year.\"\"\"\n",
    "    year = row['Year']\n",
    "    if len(year) > 4 and year[0] in '12':\n",
    "        return float(year[:4])\n",
    "    elif len(year) == 4 and year[0] in '12':\n",
    "        return float(year)\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "wiki_list['release_year'] = wiki_list.apply(lambda x: fix_year(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add 'iscult' column to movies dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to mark all cult movies as True\n",
    "wiki_list['iscult'] = True\n",
    "# Create a new dataframe that only includes the title, release year, and iscult bool.\n",
    "wiki = wiki_list.iloc[:, [3,4,5]]\n",
    "# Left merge onto movies so that all movies that match both title and year are 'True' in iscult column.\n",
    "movies = movies.merge(wiki, how='left', on=['short_title', 'release_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clean imdbId and add 'isoscars' column to movies dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format the imdbId to match the imdb data in 'oscars'\n",
    "def fix_imdb(row):\n",
    "    return 'tt' + row['imdbId']\n",
    "\n",
    "# Apply function to links dataframe.\n",
    "links['imdbId'] = links.apply(lambda x: fix_imdb(x), axis=1)\n",
    "\n",
    "# Merge movies dataframe with links dataframe to get imdbId.\n",
    "movies = movies.merge(links, on='movieId')\n",
    "# If row in movies matches row in oscars df, 'isoscars' column equals True.\n",
    "movies['isoscar'] = movies['imdbId'].isin(oscars['Const'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with ratings dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merge and drop unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings = pd.merge(full_ratings, movies, on='movieId')\n",
    "all_ratings.drop(['genres','tmdbId'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter all-ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = all_ratings[all_ratings.ratings_count > 35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take sample of ratings to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sample = ratings.sample(frac = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert timestamp to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pd.Timestamp(times_only['timestamp'][0], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_only = pd.DataFrame(full_ratings['timestamp'])\n",
    "times_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def time_conversion(row):\n",
    "    #\"\"\"Takes a row with a col titled 'timestamp' containing an int and converts to a datetime object.\"\"\"\n",
    "    #x = row['timestamp']\n",
    "    #new = datetime.datetime.fromtimestamp(x).strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    #return datetime.datetime.strptime(new, \"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "times_only['datetime'] = times_only.apply(lambda x: pd.Timestamp(x['timestamp'], unit='s'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.merge(ratings, times_only, on='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings.to_csv('ratings_clean.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Cult/Criterion/Oscars Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Team this is a function that I used to generate a column in the tag data frame indicating whether or not\n",
    "a scored tag was ever applied by a user. I am including this in our collab group because I think there are clear\n",
    "applications for creating similar columns in the movie database. Instead of joins on movie titles etc, it \n",
    "seems like we can use cult/criterion/oscar dfs as references to assign a boolean designation to each movie in\n",
    "our movie df. Happy to explain more on slack etc.\"\"\"\n",
    "\n",
    "#second improved and working verion of top g!\n",
    "def top_g(x):\n",
    "    \n",
    "    try: \n",
    "        #first thing is to create the user tag, have to place in a try block because\n",
    "        #some movies do not have user tags. So you are assigning a boolean series\n",
    "        #based on whether users tagged movies with a scored tag\n",
    "        y = x.assign(user_tag = x.tag.isin(gp_tags.get_group(x.movieId.iloc[0]).tag))\n",
    "        \n",
    "    except:\n",
    "        #if you hit a key error, aka no tags, then simply assign a false boolean series\n",
    "        y = x.assign(user_tag = [False]*len(x.index))\n",
    "        \n",
    "    y = y.assign(ut_tstamp = [np.nan]*len(x.index))\n",
    "    \n",
    "    y = y.sort_values(by = 'relevance', ascending = False).iloc[0:100]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all the other relevant databases\n",
    "tags = pd.read_csv('./data/tags.csv')\n",
    "g_tags = pd.read_csv('./data/genome-tags.csv')\n",
    "g_scores = pd.read_csv('./data/genome-scores.csv')\n",
    "m_samp = pd.merge(r_samp_1,movies, on='movieId')\n",
    "gp_tags = tags.groupby('movieId')\n",
    "g_score_m = pd.merge(g_scores,g_tags, on='tagId')\n",
    "#now group scores by movieId, and get the first group to work as a sample\n",
    "#sort g score merge by movie id may relieve the weird error I am having later\n",
    "g_score_m = g_score_m.sort_values(by = 'movieId')\n",
    "g_score_m = g_score_m.reset_index(level = 0, drop = True)\n",
    "gs_gp = g_score_m.groupby(g_score_m.movieId)\n",
    "\n",
    "#second improved and working verion of top g!\n",
    "def top_g2(x):\n",
    "    \n",
    "    try: \n",
    "        #first thing is to create the user tag, have to place in a try block because\n",
    "        #some movies do not have user tags. So you are assigning a boolean series\n",
    "        #based on whether users tagged movies with a scored tag\n",
    "        y = x.assign(user_tag = x.tag.isin(gp_tags.get_group(x.movieId.iloc[0]).tag))\n",
    "        \n",
    "    except:\n",
    "        #if you hit a key error, aka no tags, then simply assign a false boolean series\n",
    "        y = x.assign(user_tag = [False]*len(x.index))\n",
    "        \n",
    "    #y = y.assign(ut_tstamp = [np.nan]*len(x.index))\n",
    "    \n",
    "    y['ut_tstamp'] = y.apply(lambda x : tag_tstamp2(x),axis = 1)\n",
    "    \n",
    "    y = y.sort_values(by = 'relevance', ascending = False).iloc[0:25]\n",
    "    \n",
    "    return y\n",
    "\n",
    "def tag_tstamp2(row):\n",
    "    \n",
    "    time_set = set()\n",
    "    \n",
    "    #cnt = row.index[0]\n",
    "    \n",
    "    if row.user_tag:\n",
    "        ttimes = gp_tags.get_group(row.movieId)\\\n",
    "            .timestamp[gp_tags.get_group(row.movieId).tag == row.tag] \n",
    "        for t in ttimes:\n",
    "            time_set.add(t)\n",
    "        \n",
    "        time_set = np.array(time_set)\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        time_set = np.nan\n",
    "        \n",
    "    \n",
    "    return time_set\n",
    "\n",
    "gs_gp4 = gs_gp.apply(top_g2)\n",
    "gs_gp4 = gs_gp4.reset_index(level = [0,1], drop = True)\n",
    "gs_gp4 = gs_gp4.groupby(gs_gp4.movieId)\n",
    "\n",
    "gs_gp4 = gs_gp.apply(top_g2)\n",
    "gs_gp4 = gs_gp4.reset_index(level = [0,1], drop = True)\n",
    "gs_gp4.to_csv('tag_upd_25.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original ingest\n",
    "\n",
    "tags = pd.read_csv('./tag_upd_25.csv')\n",
    "tags = tags.drop(labels = 'Unnamed: 0',axis=1)\n",
    "mov_tags = movies.merge(tags, how = 'left', on = 'movieId')\n",
    "\n",
    "#group by data frames\n",
    "cults = mov_tags[mov_tags.iscult == True]\n",
    "oscar = mov_tags[mov_tags.isoscar == True]\n",
    "gp_cults = cults.groupby(cults.movieId)\n",
    "gp_oscars = oscars.groupby(oscars.movieId)\n",
    "gp_cult_tags = cults.groupby(cults.tag)\n",
    "gp_oscars_tags = cults.groupby(oscars.tag)\n",
    "\n",
    "#relevant cult tags and plot\n",
    "cnt_and_rel = gp_cult_tags.describe()['relevance'].sort_values(by = 'count', ascending = False)\n",
    "cnt_and_rel['prop'] = cnt_and_rel['count']/1184\n",
    "c_c_a_2r = cnt_and_rel.iloc[0:19]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig,ax = plt.subplots(figsize = (10,8))\n",
    "ax.scatter(cnt_and_rel['mean'], cnt_and_rel['prop'],color = ['#F4D7A4'])\n",
    "ax.scatter(c_c_a_2r['mean'], c_c_a_2r['prop'])\n",
    "ax.set_title('Tags Plotted by Count and Mean Relevance Score:\\nCult Films')\n",
    "plt.xlabel('Mean Relevance Score')\n",
    "plt.ylabel('Proportion of Movies with Tag')\n",
    "fig.savefig('cnt_rel_cult.png')\n",
    "\n",
    "#relevant oscar tags and plot\n",
    "oscar_cnt_and_rel = gp_oscar.describe()['relevance'].sort_values(by = 'count', ascending = False)\n",
    "oscar_cnt_and_rel['prop'] = oscar_cnt_and_rel['count']/470\n",
    "oscar_cnt_and_rel\n",
    "o_c_a_2r = oscar_cnt_and_rel.iloc[0:23]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig,ax = plt.subplots(figsize = (10,8))\n",
    "ax.scatter(oscar_cnt_and_rel['mean'], oscar_cnt_and_rel['prop'],color = ['#F4D7A4'])\n",
    "ax.scatter(o_c_a_2r['mean'], o_c_a_2r['prop'])\n",
    "ax.set_title('Tags Plotted by Count and Mean Relevance Score:\\nOscar Films')\n",
    "plt.xlabel('Mean Relevance Score')\n",
    "plt.ylabel('Proportion of Movies with Tag')\n",
    "fig.savefig('cnt_rel_osc.png')\n",
    "\n",
    "#cult and oscars combined and plot\n",
    "both = mov_tags[(mov_tags['isoscar'] == True) & (mov_tags['iscult'] == True)]\n",
    "gp_both = both.groupby(both.tag)\n",
    "gp_mov_tags = mov_tags.groupby(mov_tags.tag)\n",
    "g_c_a_r = gp_both.describe()['relevance'].sort_values(by = 'count', ascending = False)\n",
    "g_c_a_2r = g_c_a_r.iloc[0:6]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig,ax = plt.subplots(figsize = (10,8))\n",
    "ax.scatter(g_c_a_r['mean'], g_c_a_r['count'],color = ['#F4D7A4'])\n",
    "ax.scatter(g_c_a_2r['mean'], g_c_a_2r['count'])\n",
    "ax.set_title('Tags Plotted by Count and Mean Relevance Score:\\nCult and Oscar Films')\n",
    "plt.xlabel('Mean Relevance Score')\n",
    "plt.ylabel('Count of Movies with Tag')\n",
    "fig.savefig('both.png')\n",
    "\n",
    "#all movies\n",
    "m_c_a_r = gp_mov_tags.describe()['relevance'].sort_values(by = 'count', ascending = False)\n",
    "m_c_a_r['prop'] = m_c_a_r['count']/62423\n",
    "m_c_a_2r = m_c_a_r.iloc[0:9]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig,ax = plt.subplots(figsize = (10,8))\n",
    "ax.scatter(m_c_a_r['mean'], m_c_a_r['prop'],color = ['#F4D7A4'])\n",
    "ax.scatter(m_c_a_2r['mean'], m_c_a_2r['prop'])\n",
    "ax.set_title('Tags Plotted by Count and Mean Relevance Score:\\nAll Films')\n",
    "plt.xlabel('Mean Relevance Score')\n",
    "plt.ylabel('Proportion of Movies with Tag')\n",
    "fig.savefig('cnt_rel_all.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
