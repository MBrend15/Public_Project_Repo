{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509d01c3-ad52-45ec-8c7b-865fccc42229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/19 19:02:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/19 19:02:47 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/03/19 19:02:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%run ./etl_trusted_features.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42f0df4-2e40-4ba1-b377-67488d80a85f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow --quiet\n",
    "%pip install tensorflow_gnn --quiet\n",
    "%pip install tensorflow_io --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3aecd8-3df6-4dfd-b6ac-bf81e2ede490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 19:03:00.303302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow import keras\n",
    "import tensorflow_gnn as tfgnn\n",
    "from tensorflow_gnn import runner\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411d378",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09761f9-cb24-4097-860a-251fc341aabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getFirstEventFiles():\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket = 'sapient-bucket-trusted',\n",
    "        Prefix = f'prod/graph/first_events')\n",
    "    all_files = []\n",
    "    for content in response.get('Contents', []):\n",
    "        all_files.append(content['Key'])\n",
    "        # print(content['Key'])\n",
    "    files = [f\"s3://sapient-bucket-trusted/\" + f for f in all_files if 'parquet' in f]\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffc173e-bdcf-4fc1-8c58-6b1404ddcdcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-split-a-tensorflow-dataset-into-train-validation-and-test-sets-526c8dd29438\n",
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, test_split=0.1, val_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a8ba1-5219-492b-9fa3-c583484353fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c339aa6f-e25d-453b-8d68-67928bd82e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c_col = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be526c43-eda2-4080-9b63-3970730b8998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7fecd91-1b0b-4296-a3f8-98fb7085cee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pyarrow.parquet as pq\n",
    "# import s3fs\n",
    "# s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab7121b-8fe1-4ec8-9403-1d6818fd3426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pandas_dataframe = pq.ParquetDataset('s3://sapient-bucket-trusted/prod/graph/first_events', filesystem=s3).read_pandas().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5a7fd-3bae-4f76-8b7a-4af72b2996d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de091740-cc2d-475e-905f-919bbfe816d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TENSORFLOW CONFIGURATION\n",
    "TRAIN_SIZE = 640\n",
    "SHUFFLE_BUFFER = 500\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1142c6b-5a01-4896-adc0-d5b95aa897d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonnull_ecar_cols = [\n",
    "    'id', 'objectID','actorID','object','action','hostname', 'image_path', \n",
    "    'parent_image_path', 'new_path', 'file_path', 'malicious'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2e3a69-ada6-49f7-b9f5-576eae3e63d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ce2eb1-ac9e-48d6-bb27-174a4d3ff6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7:03PM UTC on Mar 19, 2023 --- read time: 10.076992988586426 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>  (48 + 2) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|malicious| count|\n",
      "+---------+------+\n",
      "|   benign|981985|\n",
      "|malicious|  3642|\n",
      "+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "readFirstEvents().withColumn(\"malicious\", when(col('malicious') == 1, \"malicious\")\n",
    "                                            .otherwise(\"benign\")) \\\n",
    "                .groupBy(\"malicious\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e3cd8b-5c86-4ddd-bc99-d1177cb2fd77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7:03PM UTC on Mar 19, 2023 --- read time: 5.300315856933594 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = readFirstEvents().select(*nonnull_ecar_cols).cache() \\\n",
    "                    .withColumn(\"malicious\", when(col('malicious') == 1, \"malicious\")\n",
    "                                            .otherwise(\"benign\")) \\\n",
    "                    .withColumn('order', row_number().over(Window.partitionBy(lit('1')).orderBy(lit('1')))) \\\n",
    "                    .withColumn('actorUID', dense_rank().over(Window.partitionBy().orderBy('actorID'))-1).orderBy('order') \\\n",
    "                    .withColumn('objectUID', dense_rank().over(Window.partitionBy().orderBy('objectID'))-1).orderBy('order') \\\n",
    "                    .withColumn('id', dense_rank().over(Window.partitionBy().orderBy('objectID'))-1).orderBy('order') \\\n",
    "                    .drop('order') \\\n",
    "                    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "940f2d0f-3a87-4eed-a680-64fc58564399",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "objectID                  0\n",
       "actorID                   0\n",
       "object                    0\n",
       "action                    0\n",
       "hostname                  0\n",
       "image_path            95767\n",
       "parent_image_path    739191\n",
       "new_path             980621\n",
       "file_path            345123\n",
       "malicious                 0\n",
       "actorUID                  0\n",
       "objectUID                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293751ff-22df-40bc-9634-5017541a28a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab300c7-84fe-4663-a560-1cd4a0e2ae31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'objectID', 'actorID', 'object', 'action', 'hostname',\n",
       "       'image_path', 'parent_image_path', 'new_path', 'file_path', 'malicious',\n",
       "       'actorUID', 'objectUID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec25dd52-2517-4782-b4c7-bd0982825040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actorUID</th>\n",
       "      <th>objectUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>377215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>213836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actorUID  objectUID\n",
       "0         0     377215\n",
       "1         0          0\n",
       "2         1         24\n",
       "3         2     213836\n",
       "4         2         40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number representation worked\n",
    "df[['actorUID','objectUID']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767a442-ef70-4bb7-8163-7b804c720a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeabbd6e-917f-4d15-a7b3-79e36df76794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the source and destination indices\n",
    "src_idx = df['actorUID'].tolist()\n",
    "dst_idx = df['objectUID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e99fae4-a53a-4774-8afa-618ff1e51cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the node features\n",
    "node_features = df[['parent_image_path', 'file_path']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c087e541-acac-4291-ae23-bef99fe56acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the edge features\n",
    "edge_features = df[['id']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "634148aa-d648-4887-98d4-d55bd6af0b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 19:03:54.443199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.446823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.447443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.448270: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 19:03:54.448895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.449485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.450060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.900259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.901061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.901647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 19:03:54.902232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 880 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Create the sparse adjacency matrix\n",
    "num_nodes = len(set(src_idx + dst_idx))\n",
    "indices = list(zip(src_idx, dst_idx))\n",
    "values = [1] * len(indices)\n",
    "adj_matrix = tf.sparse.SparseTensor(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    dense_shape=[num_nodes, num_nodes]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "561061a8-cb9c-4f70-a5d3-e61d66cfc334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the sparse tensor for the edge features\n",
    "edge_feature_tensor = tf.SparseTensor(\n",
    "    indices=indices,\n",
    "    values=tf.reshape(edge_features, [-1]),\n",
    "    dense_shape=[num_nodes, edge_features.shape[1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423cfb7a-c798-4ce5-99db-f8732847b8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_schema = tfgnn.read_schema(\"./graph_schema.pbtxt\")\n",
    "gtspec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4911158e-1c45-49a9-a822-59439d33611c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {'malicious': RaggedTensorSpec(TensorShape([1, None]), tf.string, 1, tf.int32)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'objectID': NodeSetSpec({'features': {'file_path': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32), 'base_address': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32), 'image_path': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'actorID': NodeSetSpec({'features': {'parent_image_path': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'id': EdgeSetSpec({'features': {'event_minute': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'event_hour': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'event_day': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'actorID', '#index.1': 'objectID'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6f430d1-f9e9-436b-b0c9-06a21cc82c17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 07:39:38.920187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-15 07:39:38.920236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-16-10-147.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\n",
      "2023-03-15 07:39:38.921158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "gt = tfgnn.random_graph_tensor(gtspec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f292a6",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb861b-fe2e-42a1-a3c3-0191049e77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_tensor(df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "    context_spec = tfgnn.ContextSpec.from_field_specs(\n",
    "        features_spec ={\n",
    "            \"malicious\": np.array(df['malicious'],\n",
    "                                dtype='string').reshape(len(df),1)\n",
    "        }),\n",
    "    node_sets = {\n",
    "        \"actorID\": tfgnn.NodeSet.from_fields(\n",
    "            sizes = [len(df)],\n",
    "            features ={\n",
    "                'parent_image_path': np.array(df['parent_image_path'],\n",
    "                                dtype='string').reshape(len(df),1)\n",
    "            }),\n",
    "        \"objectID\": tfgnn.NodeSet.from_fields(\n",
    "            sizes = [len(df)],\n",
    "            features ={\n",
    "                'base_address': np.array(df['base_address'],\n",
    "                                 dtype='string').reshape(len(df),1),\n",
    "                'file_path': np.array(df['file_path'],\n",
    "                                   dtype='string').reshape(len(df),1),\n",
    "                'image_path': np.array(df['image_path'],\n",
    "                                   dtype='string').reshape(len(df),1),\n",
    "            })\n",
    "    },\n",
    "    edge_sets ={\n",
    "        \"id\": tfgnn.EdgeSet.from_fields(\n",
    "            sizes = [len(df)],\n",
    "            features = {\n",
    "                'id': np.array(df['id'],\n",
    "                                      dtype='string').reshape(len(df),1)},\n",
    "            adjacency = tfgnn.Adjacency.from_indices(\n",
    "                source = (\"actorID\", np.array(df['actorID'], dtype='string')),\n",
    "                target = (\"objectID\", np.array(df['objectID'], dtype='string')))),\n",
    "  })\n",
    "\n",
    "    return graph_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896fa31",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45725fd-3888-4337-bdaf-d25d5d0f8bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2612a47-a4c4-410a-badf-012121748778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b607bc68-7b85-44d6-a2a7-2db6f10e2e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodes = dict()\n",
    "nodes_list = list(set(df['actorUID']) | set(df['objectUID']))\n",
    "for i, node in enumerate(nodes_list):\n",
    "    nodes[node] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "589623ac-97a6-407b-ac10-220bbdf59d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create edges of source and destination and add them into the dictionary\n",
    "edges = []\n",
    "for index, row in df.iterrows():\n",
    "    source = nodes[row['actorUID']]\n",
    "    destination = nodes[row['objectUID']]\n",
    "    features = row.id\n",
    "    edges.append((source, destination, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ef004-f9af-4896-aa66-31328f829f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcb46f2a-f275-4345-8d05-4fc776cbf7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = [(edge[0], edge[1]) for edge in edges]\n",
    "values = [edge[2] for edge in edges]\n",
    "dense_shape = (len(nodes), len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75740011-abc3-4207-a17a-26d68091a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.array(df['actorUID'], dtype='str').reshape(len(df),1)\n",
    "# values = np.array(df['actorUID'], dtype='str').reshape(len(df),1)\n",
    "# dense_shape = (len(df['actorUID']), len(df['actorUID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcae3a3-231d-483a-98f4-d038ffd6728e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd8e9780-c27d-40e1-b7bc-bd261403b99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparse_tensor = tf.SparseTensor(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    dense_shape=dense_shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8280d0-2f9a-4426-b112-4afa292a9e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create input data\n",
    "inputs = []\n",
    "for i in range(len(nodes)):\n",
    "    inputs.append(sparse_tensor.indices[sparse_tensor.indices[:,0]==i][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965a2bb-3646-4767-ad6a-4819670eb72c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441854"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4211a55-0ca7-4550-9f81-c51925c3605d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pack_N_441854_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [2] != values[1].shape = [1] [Op:Pack] name: shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# inputs = tf.ragged.constant(inputs)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inputs_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pack_N_441854_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [2] != values[1].shape = [1] [Op:Pack] name: shape"
     ]
    }
   ],
   "source": [
    "# inputs = tf.ragged.constant(inputs)\n",
    "inputs_ds = tf.random.normal(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555dffe9-d51e-4e99-b62d-14ade9ff2f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create output data\n",
    "outputs = np.array([label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df14804-9db6-4b57-b020-aca4ba00115f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape input and output data for LSTM\n",
    "inputs_ds = tf.expand_dims(inputs_ds, axis=0)\n",
    "outputs = tf.expand_dims(outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e90040-93e1-4aaf-9c7a-0b56b4f04b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79698a48-a81d-4b67-b82d-a15ff456f145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ad0d2-76a5-48de-964e-093a71d35d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e54dfd-b6b5-4151-9f3c-90bc3c18d2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
