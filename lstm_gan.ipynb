{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb956bf-6baa-4f8e-9c83-406b29f6d49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7f3622b3-4c55-4558-8b28-119e8c5f7c92;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 135ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7f3622b3-4c55-4558-8b28-119e8c5f7c92\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/5ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/12 23:11:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/12 23:11:49 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "# prepare real data\n",
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d3f787-a592-490d-b367-ec519f653b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet(*[\"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep3/*\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2b902e-30fe-4959-ae55-af69f8df4a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c731b5c-936b-4ca1-ba92-6d886fcca913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "embedding_dim = 64\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 10000\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "training_portion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf52a230-ea5e-4c5c-89fa-8134f174eaa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of samples to make\n",
    "input_len = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8328746-3ffc-462d-a489-fa85bb87dfee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_real_samples(ds, lc=300):\n",
    "    # Calculate the number of malicious and non-malicious records\n",
    "    malicious_ds = ds.filter(col(\"malicious\") == 1).limit(lc)\n",
    "    ds_events = malicious_ds.select('event_sequence').rdd.flatMap(lambda x: x).collect()\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    # Get our training data word index\n",
    "    tokenizer.fit_on_texts(ds_events)\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_count = len(word_index)\n",
    "    train_sequences = tokenizer.texts_to_sequences(ds_events)\n",
    "    train_padded = tf.keras.utils.pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    train_ds = tf.reshape(train_padded, (-1, len(train_padded), 6, 1, 1))\n",
    "    train_labels_ds = ones((1, input_len, 6, 1, 1))\n",
    "    return train_ds, train_labels_ds, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d543fa9-75aa-46e9-8e05-011c5d6e160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb441b7-a022-4d48-bc1f-da59f5940893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75224e-867c-4ec5-ae9f-2e6155ac6f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0034ad-65ed-4ae3-840f-893a64c53d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952ce639-1593-4166-96eb-d439aadee541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_value(val, old_range, new_range):\n",
    "    \"\"\"\n",
    "    this converts a value within a range of values to an integer within another range \n",
    "    \"\"\"\n",
    "    new_val = tf.cast((val - old_range[0]) / (old_range[1] - old_range[0]) * (new_range[1] - new_range[0]) + new_range[0],tf.int32)\n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f066de-f3eb-42a0-8398-680e92209ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "# https://www.tensorflow.org/tutorials/generative/dcgan#the_generator\n",
    "def define_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_len, 6)),\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "        tf.keras.layers.Dense(6, activation='sigmoid'),\n",
    "        # tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)),\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1790003-903f-4da5-b735-5ea2b56071cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(input_len, 6, 1)), # Flatten the input tensor\n",
    "        tf.keras.layers.Embedding(100 + 1, 16),\n",
    "        tf.keras.layers.Reshape((input_len, 6, 16)), # Reshape embedding output to match Dense output\n",
    "        tf.keras.layers.Flatten(), # Flatten the output of the Embedding layer\n",
    "        tf.keras.layers.Dense(input_len * 6, activation='tanh'), # Add an additional Dense layer to get desired output shape\n",
    "        tf.keras.layers.Reshape((input_len, 6, 1)), # Reshape output to desired shape\n",
    "\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa17c43e-7f48-462d-8785-e92f7bb8892e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a0a004-b31e-4a29-a656-c12180be7d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, 6, 1], minval=1, maxval=100, dtype=tf.int32)\n",
    "    n_ds = tf.reshape(n, (-1, input_len, 6, 1))\n",
    "    return n_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0770da69-fbef-4af6-ab74-60d7e765cbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim=3, n=0):\n",
    "    # generate points in latent space\n",
    "    n_ds = generate_latent_space()\n",
    "    # predict outputs\n",
    "    X = generator.predict(n_ds, verbose=0)\n",
    "    # print(\"size of output from generator\")\n",
    "    # print(X.shape)\n",
    "    # add extra dimension to output tensor\n",
    "    X = tf.expand_dims(X, axis=-1)\n",
    "    # print(\"size of input to discriminator after expansion\")\n",
    "    # print(X.shape)\n",
    "    # create class labels\n",
    "    y = zeros((1, input_len, 6, 1, 1))\n",
    "    # print(\"size of labels to discriminator\")\n",
    "    # print(y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8385897b-64d5-41e0-8713-e5172fdba185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\", \"loss\", \"prc\", \"recall\", \"auc\", \"precision\"]\n",
    "def plot_graphs(history, metrics):\n",
    "    fig, axs = plt.subplots(nrows = 2, ncols=3, figsize=(12, 6), layout=\"constrained\")\n",
    "    for ax, m in zip(axs.flat, metrics):\n",
    "        ax.plot(history.history[m])\n",
    "        ax.plot(history.history['val_'+ m])\n",
    "        ax.set_title(f'{m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5edda647-6054-495d-b1c9-63440b1a58d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def train(g_model, d_model, gan_model, latent_dim=3, n_epochs=10, n_batch=128, n_eval=20):\n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # prepare real samples\n",
    "        # x_real, y_real = generate_fake_samples(g_model, input_len)\n",
    "        x_real, y_real, vocab = prepare_real_samples(data, lc=input_len)\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, input_len)\n",
    "        # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((1, input_len, 6, 1))\n",
    "        # create inverted labels for the fake samples\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "        # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            print('Number of epochs = %i'%(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44270b-c126-4e2d-a73e-b7a63fba8dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc156d-3e0f-4344-aa2f-4d31b7434c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0542ad7-9155-4eb3-8838-b1ba270207b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d4156-4174-4e11-8b8a-0e783bc68454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27598b89-0951-474e-a361-9c23e2edccfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test combination of generator and discriminator\n",
    "generator = define_generator()\n",
    "discriminator = define_discriminator()\n",
    "gan = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf02b4-95cb-4631-b087-f38a1ae0b8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39736d72-52ee-4d28-ba9e-e5f03a19852f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test gan created data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7745f261-9ab3-4951-8ee4-37bd86d3a915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_gan = generate_latent_space()\n",
    "# x_gan = tf.reshape(x_gan, (-1, input_len, 6, 1, 1))\n",
    "# create inverted labels for the fake samples\n",
    "y_gan = ones(([1,input_len, 6, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe4defae-dd10-4d15-a1eb-6f1c48aa2f25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 6, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35e4b6f6-dfaa-4eb0-803a-aba2e6e4662c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 1, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1412866b-31f7-4982-a797-079fbf268c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.70156478881836, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.train_on_batch(x_gan, y_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31845f7-471a-4968-a2ef-08573e257720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d8d83d-6618-4226-9c07-df26475ae41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create real gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7c08ecc-1b3a-4ca4-8c8d-fc876158effb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs = 20\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, gan, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bc4d4-1d7b-427c-b332-6afa13a59374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "770b601b-9ddf-4693-b560-ab8a505a0ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# create data based on the trained model\n",
    "si = generate_latent_space()\n",
    "sp = gan.predict(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c822232e-9384-4574-8fdf-97a8032e557d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c23b1bb2-b1d6-436c-acca-6d1b8fa2d0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=float32, numpy=\n",
       "array([[ 0.08062109],\n",
       "       [-0.02939204],\n",
       "       [ 0.12279744],\n",
       "       [-0.08814587],\n",
       "       [-0.01482284],\n",
       "       [ 0.11645006]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1e116-7337-465d-b3a7-301dbea33f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dfdd7ad-652d-42bf-ae4b-84ae119de645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Multinomial_device_/job:localhost/replica:0/task:0/device:GPU:0}} logits should be a matrix, got shape [1,6,1] [Op:Multinomial]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30259/197236478.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Multinomial_device_/job:localhost/replica:0/task:0/device:GPU:0}} logits should be a matrix, got shape [1,6,1] [Op:Multinomial]"
     ]
    }
   ],
   "source": [
    "tf.random.categorical( sp, num_samples=1)[-1, 0].numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d2d63-963f-434e-97ee-15be7c96f739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab35d3a-c627-4260-ac2e-4a3bc5e3527c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9405a3e6-0941-4e1d-a063-5bfdb0ace679",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.02939204], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b09d7-983c-4e52-8ca6-1e61b4e77ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79ed3831-299e-4e04-83f6-0590bcbbea33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6767d3e-81ce-4675-b3af-5858906b2cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30259/1693799834.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sp_ds' is not defined"
     ]
    }
   ],
   "source": [
    "len(sp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fadde8f3-3b4c-4746-90f1-cc0d268e98aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sp_ds = tf.reshape(sp, (input_len, 6, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a54f9-3a98-494a-acca-1997df07940e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adaff0cc-5c61-48fd-b81a-428ef0810fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c73575aa-5c7f-4cb8-82a0-b78558484448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30259/3791397654.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sp_ds' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(sp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "111c69cb-a2cc-4510-9c6c-33857d196b74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30259/3263551504.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sp_ds' is not defined"
     ]
    }
   ],
   "source": [
    "np.min(sp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7169b4c5-d9df-4a61-a7ac-32a13dd25b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30259/1480779426.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sp_ds' is not defined"
     ]
    }
   ],
   "source": [
    "print(sp_ds[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971b3ec-b80d-47be-91be-839e14ead591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed4a37fd-fa95-4cd2-b4f7-9b731476c9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30259/1555095351.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m table = tf.lookup.StaticHashTable(\n\u001b[1;32m      2\u001b[0m     tf.lookup.KeyValueTensorInitializer(\n\u001b[0;32m----> 3\u001b[0;31m         keys=vocab, values=tf.constant(list(range(vocab_count)),\n\u001b[0m\u001b[1;32m      4\u001b[0m                                        dtype=tf.int64)),\n\u001b[1;32m      5\u001b[0m     default_value=0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=vocab, values=tf.constant(list(range(vocab_count)),\n",
    "                                       dtype=tf.int64)),\n",
    "    default_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b38d5-520e-48fe-8734-7fe9f9056a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
