{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c605132c-ae51-48ff-98bf-b7028d120233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hands-on-generative-adversarial-networks-gan-for-signal-processing-with-python-ff5b8d78bd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a675010-0fd6-47bf-b96f-8f2bb887bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2b902e-30fe-4959-ae55-af69f8df4a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "# https://stackoverflow.com/questions/58352326/running-the-tensorflow-2-0-code-gives-valueerror-tf-function-decorated-functio\n",
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c731b5c-936b-4ca1-ba92-6d886fcca913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "embedding_dim = 64\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 10000\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "training_portion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb956bf-6baa-4f8e-9c83-406b29f6d49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-feb3118b-3bbe-4166-a619-39d44d9cf4dd;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      "downloading https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar ...\n",
      "\t[SUCCESSFUL ] graphframes#graphframes;0.8.2-spark3.2-s_2.12!graphframes.jar (73ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.16!slf4j-api.jar (31ms)\n",
      ":: resolution report :: resolve 818ms :: artifacts dl 107ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-feb3118b-3bbe-4166-a619-39d44d9cf4dd\n",
      "\tconfs: [default]\n",
      "\t2 artifacts copied, 0 already retrieved (281kB/7ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 03:48:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 03:48:09 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "# prepare real data\n",
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d3f787-a592-490d-b367-ec519f653b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet(*[\"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep3/*\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8328746-3ffc-462d-a489-fa85bb87dfee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_real_samples(ds, lc=300):\n",
    "    # Calculate the number of malicious and non-malicious records\n",
    "    malicious_ds = ds.filter(col(\"malicious\") == 1).limit(lc)\n",
    "    ds_events = malicious_ds.select('event_sequence').rdd.flatMap(lambda x: x).collect()\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    # Get our training data word index\n",
    "    tokenizer.fit_on_texts(ds_events)\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_count = len(word_index)\n",
    "    train_sequences = tokenizer.texts_to_sequences(ds_events)\n",
    "    train_padded = tf.keras.utils.pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    train_ds = tf.reshape(train_padded, (-1, len(train_padded), 6, 1, 1))\n",
    "    train_labels_ds = ones((1, input_len, 6, 1, 1))\n",
    "    return train_ds, train_labels_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d543fa9-75aa-46e9-8e05-011c5d6e160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb441b7-a022-4d48-bc1f-da59f5940893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4990288f-c540-4f30-8411-ae99dfabc4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e75224e-867c-4ec5-ae9f-2e6155ac6f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of samples to make\n",
    "input_len = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0034ad-65ed-4ae3-840f-893a64c53d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f066de-f3eb-42a0-8398-680e92209ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "# https://www.tensorflow.org/tutorials/generative/dcgan#the_generator\n",
    "def define_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_len, 6)),\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "        tf.keras.layers.Dense(6, activation='sigmoid'),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)),\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1790003-903f-4da5-b735-5ea2b56071cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(input_len, 6, 1)), # Flatten the input tensor\n",
    "        tf.keras.layers.Embedding(100 + 1, 16),\n",
    "        tf.keras.layers.Reshape((input_len, 6, 16)), # Reshape embedding output to match Dense output\n",
    "        tf.keras.layers.Flatten(), # Flatten the output of the Embedding layer\n",
    "        tf.keras.layers.Dense(input_len * 6, activation='tanh'), # Add an additional Dense layer to get desired output shape\n",
    "        tf.keras.layers.Reshape((input_len, 6, 1)) # Reshape output to desired shape\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa17c43e-7f48-462d-8785-e92f7bb8892e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74a0a004-b31e-4a29-a656-c12180be7d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_latent_space():\n",
    "    n = tf.random.uniform(shape=[input_len, 6, 1], minval=1, maxval=100, dtype=tf.int32)\n",
    "    n_ds = tf.reshape(n, (-1, input_len, 6, 1))\n",
    "    return n_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0770da69-fbef-4af6-ab74-60d7e765cbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim=3, n=0):\n",
    "    # generate points in latent space\n",
    "    n_ds = generate_latent_space()\n",
    "    # predict outputs\n",
    "    X = generator.predict(n_ds, verbose=0)\n",
    "    print(\"size of output from generator\")\n",
    "    print(X.shape)\n",
    "    # add extra dimension to output tensor\n",
    "    X = tf.expand_dims(X, axis=-1)\n",
    "    print(\"size of input to discriminator after expansion\")\n",
    "    print(X.shape)\n",
    "    # create class labels\n",
    "    y = zeros((1, input_len, 6, 1, 1))\n",
    "    print(\"size of labels to discriminator\")\n",
    "    print(y.shape)\n",
    "    return X, y\n",
    "\n",
    "# def generate_fake_samples(generator, latent_dim=3, n=0):\n",
    "#     # generate points in latent space\n",
    "#     n_ds = generate_latent_space()\n",
    "#     # predict outputs\n",
    "#     X = generator.predict(n_ds, verbose=0)\n",
    "#     # create class labels\n",
    "#     y = zeros((1, input_len, 6, 1, 1))\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5edda647-6054-495d-b1c9-63440b1a58d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def train(g_model, d_model, gan_model, latent_dim=3, n_epochs=5, n_batch=128, n_eval=200):\n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # prepare real samples\n",
    "        # x_real, y_real = generate_fake_samples(g_model, input_len)\n",
    "        x_real, y_real = prepare_real_samples(data, lc=input_len)\n",
    "        # prepare fake examples using the generator\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, input_len)\n",
    "        # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_space()\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((1, input_len, 6, 1))\n",
    "        # create inverted labels for the fake samples\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "        # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            plt.title('Number of epochs = %i'%(i+1))\n",
    "            pred_data = generate_fake_samples(generator, input_len)[0]\n",
    "            real_data  = generate_fake_samples(generator, input_len)[0]\n",
    "            plt.plot(pred_data[0],'.',label='Random Fake Sample',color='firebrick')\n",
    "            plt.plot(real_data[0],'.',label = 'Random Real Sample',color='navy')\n",
    "            plt.legend(fontsize=10)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44270b-c126-4e2d-a73e-b7a63fba8dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d4156-4174-4e11-8b8a-0e783bc68454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45fca2d2-1645-418a-873f-90a00ec9fcb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create test combination of generator and discriminator\n",
    "ge = define_gen2()\n",
    "disc = define_discriminator()\n",
    "gan_m = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27598b89-0951-474e-a361-9c23e2edccfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test combination of generator and discriminator\n",
    "generator = define_generator()\n",
    "discriminator = define_discriminator()\n",
    "gan = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3d3fb90-8747-4cd1-9bd1-3187905c754f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab9da932-64e2-4249-bcfb-aea9adb4ae29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of output from generator\n",
      "(1, 3000, 500)\n",
      "size of input to discriminator after expansion\n",
      "(1, 3000, 500, 1)\n",
      "size of labels to discriminator\n",
      "(1, 500, 6, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "x_real, y_real = generate_fake_samples(ge, input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d531ebb3-5a7c-4876-9be3-41ecd45e2363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3000, 500, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "077d74c0-9ccc-4e89-852c-349b073f0522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500, 6, 1, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf02b4-95cb-4631-b087-f38a1ae0b8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09540da-4b61-42f8-9863-e15c6c8d5a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use discriminator with generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e53e7bcb-7a5c-48ad-8880-dd7039cdb79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "disc.train_on_batch(x_real, y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39736d72-52ee-4d28-ba9e-e5f03a19852f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test gan created data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745f261-9ab3-4951-8ee4-37bd86d3a915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_gan = generate_latent_space()\n",
    "# x_gan = tf.reshape(x_gan, (-1, input_len, 6, 1, 1))\n",
    "# create inverted labels for the fake samples\n",
    "y_gan = ones(([1,input_len, 6, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4defae-dd10-4d15-a1eb-6f1c48aa2f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e4b6f6-dfaa-4eb0-803a-aba2e6e4662c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412866b-31f7-4982-a797-079fbf268c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "disc.train_on_batch(x_gan, y_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31845f7-471a-4968-a2ef-08573e257720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d803ad-611e-41fc-9bbb-d27713b385a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan_m.train_on_batch(x_gan, y_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563cf8d-39d9-4043-8130-9da6a09b4975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6636408-9b19-4ed7-aa46-2dbd536131af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8d83d-6618-4226-9c07-df26475ae41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create real gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7c08ecc-1b3a-4ca4-8c8d-fc876158effb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input to generator\n",
      "(1, 500, 6, 1)\n",
      "size of labels to discriminator\n",
      "(1, 500, 6, 1, 1)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, gan, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bc4d4-1d7b-427c-b332-6afa13a59374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "770b601b-9ddf-4693-b560-ab8a505a0ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 729ms/step\n"
     ]
    }
   ],
   "source": [
    "# create data based on the trained model\n",
    "si = generate_latent_space()\n",
    "sp = gan.predict(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79ed3831-299e-4e04-83f6-0590bcbbea33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500, 6, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fadde8f3-3b4c-4746-90f1-cc0d268e98aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp_ds = tf.reshape(sp, (input_len, 6, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "677a54f9-3a98-494a-acca-1997df07940e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([500, 6, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c73575aa-5c7f-4cb8-82a0-b78558484448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388734"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adaff0cc-5c61-48fd-b81a-428ef0810fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169b4c5-d9df-4a61-a7ac-32a13dd25b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
