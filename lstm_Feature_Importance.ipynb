{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68a996a-cf43-4787-8cd2-a8216a97cf3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use kernel conda_tensorflow2_p310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d7fa78-5461-4d9a-897d-b14452f45396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import feature_column\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f876fa6b-6c75-4b3e-9bf2-4f664f948320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f953d05f-dcf9-4a60-8583-245b47ed15e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c720fdc8-e742-424d-ba73-ecf73bdba17b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 134ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c720fdc8-e742-424d-ba73-ecf73bdba17b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/5ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/08 17:13:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/08 17:13:36 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/04/08 17:13:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "%run ./read_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2463851b-bfd8-40a2-8f3a-e9f9fd96faa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/68036975/valueerror-shape-must-be-at-least-rank-3-but-is-rank-2-for-node-biasadd\n",
    "# config for rank error in lstm\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "pd.set_option('display.max_columns', None)\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb4fe4d-f90f-4bec-8e95-0132f34e0306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Config\n",
    "embedding_dim = 64\n",
    "max_length = 6\n",
    "sequence_length = 6\n",
    "max_features = 10000\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "training_portion = 0.8\n",
    "\n",
    "hparams = {\n",
    "    \"batch_size\": 128,\n",
    "    \"cnn_filter_sizes\": [128, 128, 128],\n",
    "    \"cnn_kernel_sizes\": [5, 5, 5],\n",
    "    \"cnn_pooling_sizes\": [5, 5, 40],\n",
    "    \"constraint_learning_rate\": 0.01,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"embedding_trainable\": False,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"max_num_words\": 10000,\n",
    "    \"max_sequence_length\": 250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e983d02-5280-46ca-800c-2bd1be6f9c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 17:13:38.306188: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444c90ae-dfb5-480e-aab8-6be04dbd673e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds = spark.read.parquet(\"s3a://sapient-bucket-trusted/prod/tensor_sample_data/test_holdout/*\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b8f10ae-1b58-4bea-8e29-903ef84558ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tot = ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2069773-8276-40a4-b274-ff3bb2444f81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ds = spark.read.parquet(*[\"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep3/*\",\n",
    "                          \"s3a://sapient-bucket-trusted/prod/graph/encoded/real/23Sep6/*\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f1a4171-e551-450c-9fd2-5e00fab51b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tot = ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece39c3b-b3e0-465e-be27-c25cad010917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------------+\n",
      "|mal_trace|cnt_per_group|perc_of_count_total|\n",
      "+---------+-------------+-------------------+\n",
      "|        1|       247127| 0.7781506573127496|\n",
      "|        0|     31511119|  99.22184934268725|\n",
      "+---------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.groupBy(\"mal_trace\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'cnt_per_group') \\\n",
    "    .withColumn('perc_of_count_total', (col('cnt_per_group') / tot) * 100 ) \\\n",
    "    .sort(\"perc_of_count_total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a57429b9-d6c4-4950-8156-c57d49febd31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mal_count = ds.where( col(\"mal_trace\") == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5979c0f9-a145-4c38-85cd-7b78fa8933d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = spark.read.parquet(\"s3a://sapient-bucket-trusted/prod/tensor_sample_data/test_holdout/*\").cache().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "466d55ae-638f-4e81-b9bd-46507460121c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# can we filter and convert to lists without using pandas?\n",
    "df = ds.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbdca15f-a656-4c49-9f2b-e8fe9eadd3df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31758246"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0546378f-ef00-44ba-a7b2-dbfc142e87d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trace               int64\n",
       "mal_trace           int32\n",
       "malicious         float64\n",
       "event_sequence     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76bab517-cec8-4b65-98ec-1117d7b0a717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_b = df[df['mal_trace'] == 0]\n",
    "df_m = df[df['mal_trace'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f15afcd2-9ec3-4ddc-97f5-b859e9374ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_b_downsampl = resample(df_b, \n",
    "                        replace = False, \n",
    "                        n_samples = len(df_m),\n",
    "                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e79b201-8138-45d7-9439-0cca43595651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247127, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b_downsampl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c74df79-e8a8-4e32-a888-608be29d00b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247127, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6e9aaa6-a2e7-4f4e-bf07-bfe3e42b4c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_down = pd.concat([df_m, df_b_downsampl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8b74d20-6be2-4688-b74f-21603f16af7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data conversion - https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d91bfd-d7d6-4fae-8725-4d0d11fcd814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c896d4c7-5f16-48ff-b12f-865e6ac9ffb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39748660/how-to-perform-k-fold-cross-validation-with-tensorflow\n",
    "def make_dataset(X_data,y_data,n_splits):\n",
    "\n",
    "    def gen():        \n",
    "        for train_index, test_index in KFold(n_splits).split(X_data):\n",
    "            X_train, X_test = X_data[train_index], X_data[test_index] # input\n",
    "            y_train, y_test = y_data[train_index], y_data[test_index] # labels\n",
    "            \n",
    "            X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "            X_train_ds = tf.reshape(X_train_seq, (len(X_train_seq),6,1))\n",
    "            \n",
    "            X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "            X_test_ds = tf.reshape(X_test_seq, (len(X_test_seq),6,1))\n",
    "            \n",
    "            y_test_ds = tf.ragged.constant(y_train)\n",
    "            y_test_ds = tf.ragged.constant(y_test)\n",
    "            \n",
    "            \n",
    "            yield X_train_ds,y_train_ds,X_test_ds,y_test_ds\n",
    "\n",
    "    return tf.data.Dataset.from_generator(gen, (tf.float64,tf.float64,tf.float64,tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64db1bc7-9d32-40ba-80ee-d512ac8e6522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset=make_dataset(df_events,df_labels,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c234c7-d78a-462e-b299-d8bc2bde0abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ebde825-28b7-428d-9cdc-74cf9205f49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_events = df_down['event_sequence'].tolist()\n",
    "df_labels = df_down['malicious'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4b611c5-b8a5-4b62-8993-8b381b036734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3054c2b-6e5f-4835-9c92-d8a830c6fa86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "vocab_count = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42c6f262-0d91-4800-bac9-ef3ef29f07ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for X_train,y_train,X_test,y_test in iter(dataset):\n",
    "#     print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89221450-0c45-41c5-9235-3454bf5d7b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b42de-1fa7-46a5-bc78-ef0974579eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b173e8e-fa2a-456c-bd9e-d06584d48bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22779/2290901658.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_set, validation_set, train_labels, validation_labels = train_test_split(df_events, df_labels,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                     \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                     test_size=0.2)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2441\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2443\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     return list(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \"\"\"\n\u001b[0;32m-> 2022\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2023\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "train_set, validation_set, train_labels, validation_labels = train_test_split(df_events, df_labels,\n",
    "                                                    stratify=df_labels, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89599879-190a-4a20-943c-a6e7ca52e30f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2561/906755659.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
     ]
    }
   ],
   "source": [
    "Counter(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb27c9-bf73-43fc-9836-5237db243af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff37e76-c6bc-46da-8a72-00cc3da89c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8122f80-6f2b-4cd8-bc07-3a05679892b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2561/3851691376.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrunc_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_set)\n",
    "train_padded = tf.keras.utils.pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e27a69-e616-4749-91f5-eaa734d351cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences(validation_set)\n",
    "validation_padded = tf.keras.utils.pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a85a86-767e-400f-9ce3-81c4fe49da71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956ebec-6469-4eed-a381-aa6b21c42940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29722db5-1a09-4859-a597-41d9269bc238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916d14c-59b3-40be-bc85-5fa4245c7c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6489d93-f1c8-4c66-8386-ba0e9028b181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = tf.reshape(train_padded, (len(train_padded),6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10d08f-5439-4a78-811b-7f8a625c5b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_ds = tf.reshape(validation_padded, (len(validation_padded),6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a3627-b45c-4362-a7eb-0742ee49131c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_ds = tf.ragged.constant(train_labels)\n",
    "validation_labels_ds = tf.ragged.constant(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623d73d-440a-4955-8851-447033fbc72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ba257-4a77-4b99-beb9-7d8ece95b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea8277-6b5f-4ba2-b3d2-f3ed2d5678a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b3cc0-18cc-4da5-85f3-f4f0b3640903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_labels_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2fa82-e1ea-4721-8d22-789811a4b41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f14c9-383e-4f88-9cd0-ace2e657b0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Embedding(vocab_count + 1, 16))\n",
    "model.add(keras.layers.LSTM(500, input_shape=(train_ds.shape[1], train_ds.shape[2]), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(300, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(200))\n",
    "model.add(keras.layers.Dense(train_ds.shape[2], activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb79f49-7b94-43b8-8e06-73763a49df23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfee1da-8c36-49c0-bcf0-cc3ce098c3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892dda7-4340-4232-b8a9-48878c17a056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "                x=train_ds,\n",
    "                y=train_labels_ds,\n",
    "                batch_size=128,\n",
    "                epochs=100,\n",
    "                verbose=0,\n",
    "                callbacks=None,\n",
    "                validation_split=0.0,\n",
    "                validation_data=(validation_ds, validation_labels_ds),\n",
    "                shuffle=True,\n",
    "                class_weight=None,\n",
    "                sample_weight=None,\n",
    "                initial_epoch=0,\n",
    "                steps_per_epoch=None,\n",
    "                validation_steps=None,\n",
    "                validation_batch_size=None,\n",
    "                validation_freq=1,\n",
    "                max_queue_size=10,\n",
    "                workers=1,\n",
    "                use_multiprocessing=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c0d6c-ecd7-4fee-b711-168681194c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce2e90-3f9b-46ed-936a-a3ef1494850b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")\n",
    "plot_graphs(history, \"prc\")\n",
    "plot_graphs(history, \"recall\")\n",
    "plot_graphs(history, \"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e63dc-5da3-4963-a1f0-9cbb4e2769b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot(history.history[\"accuracy\"])\n",
    "# plt.plot(history.history['val_'+\"accuracy\"])\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.legend([\"accuracy\", 'val_'+\"accuracy\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23adc5-ff86-4815-b075-b8aeca0bc9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835457a-1be9-4544-9754-43f9d2d7d4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
    "    tf.keras.layers.Embedding(100 + 1, 128, input_length=6),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb5846-ea0a-422e-9cb7-f4e93b042ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a629d3-2484-4024-afad-52db6a0caf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b441ed2-6561-488b-b196-92568a84dce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "history = model.fit(train_padded, train_ds, epochs=num_epochs, \n",
    "                    validation_data=(validation_padded, validation_ds), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25487fa8-f41c-42c8-8d6e-e4ce28c9afd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ca34a-ba1a-457d-9645-a3efc25c6914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9542f-b32e-4be8-8051-f93fd8a7ad16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf71b1c-60cd-4e08-986c-356975e9846c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c87225-223b-4560-834b-e8d5fa3f1769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds = tf.data.Dataset.from_tensor_slices(([i for i in df['event_sequence']], df['Trace'], df['malicious']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906da94f-83b9-4e39-bf12-e2f85020c471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input data based on - https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda2c41-636d-4818-86b9-6f02a4eff507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92187562-6f81-4256-8f5e-d9cb67eb999e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77558b0-2982-4909-8721-9063183a35b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('malicious')\n",
    "  ds = tf.data.Dataset.from_tensor_slices(([i for i in df['event_sequence']], df['malicious']))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2cd60-bf09-40ec-995f-3704dee0f926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A utility method to create a feature column\n",
    "# and to transform a batch of data\n",
    "def make_features(feature_column):  \n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7865ee9-305a-4030-b338-a7ad6d61eb1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b65b7a-a549-44a5-b68f-7ad316ff7ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e5b50-1228-4da2-9d52-363ea1c3b2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(set([x[0] for x in df['event_sequence']] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bd256-a538-4e91-af6c-55ebc9d553f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4b960-15fb-4d72-9a0f-5c877aeb608c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = vocab_size\n",
    "sequence_length = 6\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length.\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6516a77-080b-409c-88f8-0706b71c2e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dceee2-19ea-4bd8-a237-f4642150c1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc404c7-0e0c-431a-bdd9-46feff911b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ee91f-e564-435f-981b-cb9d2db6791d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(tf.reshape(text_ds, (len(text_ds),6,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9c9b2-560e-46cf-9f4a-d7bc3a3df9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sequence_batch, label_batch in train_ds.take(1):\n",
    "  print('A batch of sequences:', sequence_batch ) # list(feature_batch.keys()))\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed4bec-e032-4c50-8040-403dca30bd64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  #feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb9974-c737-4ee1-bfcb-9ca73fdb8bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0fb3b-6c0b-477a-9713-33d2e3fbd03f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915759f0-6308-480c-b4ca-40ea8578738c",
   "metadata": {},
   "source": [
    "#### Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121cb81d-4974-47dc-ab8c-3a1e62cb06ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Select a background dataset to estimate expected values\n",
    "background_data = train_ds[np.random.choice(train_ds.shape[0], 100, replace=False)]\n",
    "\n",
    "# Create an explainer object for the LSTM model\n",
    "explainer = shap.DeepExplainer(model, background_data)\n",
    "\n",
    "# Choose a dataset for which you want to calculate SHAP values\n",
    "sample_data = validation_ds[:10]  # Adjust the sample size as needed\n",
    "\n",
    "# Compute SHAP values for the selected dataset\n",
    "shap_values = explainer.shap_values(sample_data)\n",
    "\n",
    "# Plot the SHAP values\n",
    "shap.summary_plot(shap_values, sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608f9fb-dfb1-478b-917f-3c1eadd25033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9a2ea-7587-479f-a058-fb86c06767a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc39d51-9ae4-4e9a-bc2d-c191fb968110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499ce4c-9627-4a04-a5d0-567c7d2f0c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a371f8e-63ac-4a4d-a2d6-85d3b3f65c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736f048-6568-44ec-bde1-e8696bedcc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
